import akshare as ak
import random
import json
import pandas as pd
from datetime import datetime, timedelta, date
from typing import List, Dict, Any
from openai import OpenAI
import os
from pathlib import Path
import smtplib
from email.mime.text import MIMEText
import time as t

def send_email(subject: str, body: str, receivers: List[str], sender: str, password: str, file_path: str = None) -> bool:
    """å‘é€é‚®ä»¶å¹¶è¿”å›æ˜¯å¦æˆåŠŸ"""
    # åˆ›å»ºæ–‡æœ¬é‚®ä»¶
    msg = MIMEText(body, 'plain', 'utf-8')
    msg['From'] = sender  # å‘ä»¶äºº
    msg['To'] = ', '.join(receivers)  # å°†æ”¶ä»¶äººåˆ—è¡¨è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
    msg['Subject'] = subject

    # SMTPæœåŠ¡å™¨è®¾ç½®
    smtp_server = 'applesmtp.163.com'
    smtp_port = 465

    # ç™»å½•å‡­è¯ï¼ˆä½¿ç”¨æˆæƒç ï¼‰
    username = sender

    # å‘é€é‚®ä»¶
    try:
        server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        server.login(username, password)
        server.sendmail(sender, receivers, msg.as_string())
        server.quit()
        print("é‚®ä»¶å‘é€æˆåŠŸï¼")
        # å¦‚æœé‚®ä»¶å‘é€æˆåŠŸä¸”æä¾›äº†æ–‡ä»¶è·¯å¾„ï¼Œåˆ™åˆ é™¤æœ¬åœ°æ–‡ä»¶
        if file_path and os.path.exists(file_path):
            #os.remove(file_path)
            print(f"æœ¬åœ°æ–‡ä»¶ {file_path} å·²åˆ é™¤")
        return True
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼š{e}")
        return False

def load_config(config_file: str, keys_file: str) -> Dict[str, Any]:
    """è¯»å– JSON é…ç½®æ–‡ä»¶å¹¶è¿”å›é…ç½®å­—å…¸"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        with open(keys_file, 'r', encoding='utf-8') as f:
            keys = json.load(f)
        config.update(keys)  # åˆå¹¶ keys.json ä¸­çš„é…ç½®
        return config
    except Exception as e:
        raise Exception(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

def select_stocks(config: Dict[str, Any]) -> List[str]:
    """æ ¹æ®é…ç½®æ–‡ä»¶é€‰æ‹©è‚¡ç¥¨"""
    if config['stock_selection'] == 'specified':
        return config['specified_stocks']
    elif config['stock_selection'] == 'random':
        all_stocks = ak.stock_zh_a_spot_em()['ä»£ç '].tolist()
        return random.sample(all_stocks, min(config['random_stock_count'], len(all_stocks)))
    else:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­çš„ 'stock_selection' å¿…é¡»æ˜¯ 'specified' æˆ– 'random'")

def get_trading_dates(start_date: str, end_date: str) -> List[str]:
    """
    è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„äº¤æ˜“æ—¥åˆ—è¡¨ã€‚
    
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: list, äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œæ ¼å¼ä¸º 'YYYYMMDD'
    """
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    start_date_dt = pd.to_datetime(start_date)
    end_date_dt = pd.to_datetime(end_date)
    trading_dates = calendar[(calendar['trade_date'] >= start_date_dt) & 
                             (calendar['trade_date'] <= end_date_dt)]['trade_date']
    return trading_dates.dt.strftime('%Y%m%d').tolist()

def get_intraday_data(stock: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„åˆ†æ—¶æˆäº¤æ•°æ®ã€‚
    
    :param stock: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: pd.DataFrame, åˆ†æ—¶æˆäº¤æ•°æ®ï¼Œsymbol å’Œ name åˆ—å·²åˆ é™¤
    """
    # æ ¹æ®è‚¡ç¥¨ä»£ç å‰ç¼€è°ƒæ•´åˆ†é’Ÿçº¿ä»£ç 
    if stock.startswith('688'):
        minute_code = f"sh{stock}"
    elif stock.startswith(('83', '43', '87')):
        minute_code = f"bj{stock}"
    elif stock.startswith('60'):
        minute_code = f"sh{stock}"
    elif stock.startswith(('00', '30')):
        minute_code = f"sz{stock}"
    else:
        minute_code = stock
    print(f"minute_code: {minute_code}")

    trading_dates = get_trading_dates(start_date, end_date)
    stock_data_list = []
    for date in trading_dates:
        max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        for attempt in range(max_retries):
            try:
                daily_data = ak.stock_intraday_sina(symbol=minute_code, date=date)
                if not daily_data.empty:
                    daily_data['ticktime'] = pd.to_datetime(date + ' ' + daily_data['ticktime'])
                    stock_data_list.append(daily_data)
                    print(f"æˆåŠŸè·å– {minute_code} åœ¨ {date} çš„æ•°æ®")
                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œç­‰å¾… 2 åˆ†é’Ÿ
                    if date != trading_dates[-1]:
                        print("ç¨ç­‰ä¸€ä¸‹...")
                        for _ in range(random.randint(1, 10)):  # ç­‰å¾…éšæœºç§’æ•°ï¼Œæ¯ç§’æ‰“å°ä¸€ä¸ªâ€œ.â€
                            print(".", end="", flush=True)
                            t.sleep(1)
                        print()  # æ¢è¡Œ
                    break  # æˆåŠŸè·å–æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
            except Exception as e:
                print(f"è·å–è‚¡ç¥¨ {minute_code} åœ¨ {date} çš„æ•°æ®æ—¶å‡ºé”™: {e}")
                if attempt < max_retries - 1:  # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…é‡è¯•
                    print("ç­‰å¾…20ç§’åé‡è¯•...")
                    for _ in range(10):  # ç­‰å¾…600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰ï¼Œæ¯2ç§’æ‰“å°ä¸€ä¸ªâ€œ.â€
                        print(".", end="", flush=True)
                        t.sleep(2)
                    print()  # æ¢è¡Œ
                else:
                    print(f"è‚¡ç¥¨ {minute_code} åœ¨ {date} çš„æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡")
                    break  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³å‡ºå¾ªç¯

    if not stock_data_list:
        raise ValueError(f"æ— æ³•è·å– {minute_code} çš„é€ç¬”æˆäº¤æ•°æ®")
    stock_name = daily_data['name'][0]
    all_data = pd.concat(stock_data_list)
    all_data = all_data.sort_values('ticktime').reset_index(drop=True)
    all_data = all_data.drop(columns=['symbol', 'name'], errors='ignore')
    return all_data, stock_name

def get_daily_kline_data(symbol: str, end_date: str, kline_days: int) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨æœ€è¿‘ kline_days ä¸ªäº¤æ˜“æ—¥çš„æ—¥Kçº¿æ•°æ®ã€‚
    
    :param symbol: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '300680'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, éœ€è¦çš„äº¤æ˜“æ—¥æ•°é‡ï¼Œä¾‹å¦‚ 60
    :return: pd.DataFrame, æ—¥Kçº¿æ•°æ®
    """
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    end_dt = pd.to_datetime(end_date)
    
    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ <= end_dtï¼Œé™åºæ’åºï¼Œå–å‰ kline_days ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
    trading_dates_filtered = calendar[calendar['trade_date'] <= end_dt]['trade_date'].sort_values(ascending=False).head(kline_days)
    
    if len(trading_dates_filtered) < kline_days:
        print(f"Warning: Only {len(trading_dates_filtered)} trading days available up to {end_date}")
    
    start_dt_kline = trading_dates_filtered.iloc[-1]  # æœ€æ—©çš„æ—¥æœŸåœ¨æœ€åé¢ï¼Œå› ä¸ºæ˜¯é™åº
    end_dt_kline = trading_dates_filtered.iloc[0]  # æœ€æ™šçš„æ—¥æœŸåœ¨æœ€å‰é¢
    
    start_date_kline = start_dt_kline.strftime('%Y%m%d')
    end_date_kline = end_dt_kline.strftime('%Y%m%d')
    
    # è·å–æ—¥Kçº¿æ•°æ®
    stock_data = ak.stock_zh_a_hist(symbol=symbol, period="daily", start_date=start_date_kline, end_date=end_date_kline, adjust="")
    return stock_data

def get_market_index_data(stock_code: str, start_date: str, end_date: str) -> tuple:
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç è·å–å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°æ—¥Kçº¿æ•°æ®å’ŒæŒ‡æ•°åç§°ã€‚

    :param stock_code: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: tuple, (pd.DataFrame, str) - å¤§ç›˜æŒ‡æ•°æ—¥Kçº¿æ•°æ®å’ŒæŒ‡æ•°åç§°
    """
    print(f"æ­£åœ¨è·å–è‚¡ç¥¨ {stock_code} å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°æ•°æ®...")

    # æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šå¤§ç›˜æŒ‡æ•°
    if stock_code.startswith(('60', '688')):
        index_code = "000001"  # ä¸Šè¯æŒ‡æ•°
        index_name = "ä¸Šè¯æŒ‡æ•°"
        print(f"è¯†åˆ«ä¸ºä¸Šæµ·å¸‚åœºè‚¡ç¥¨ï¼Œä½¿ç”¨ä¸Šè¯æŒ‡æ•° ({index_code})")
    elif stock_code.startswith(('00', '30')):
        index_code = "399001"  # æ·±åœ³æˆæŒ‡
        index_name = "æ·±åœ³æˆæŒ‡"
        print(f"è¯†åˆ«ä¸ºæ·±åœ³å¸‚åœºè‚¡ç¥¨ï¼Œä½¿ç”¨æ·±åœ³æˆæŒ‡ ({index_code})")
    elif stock_code.startswith(('83', '43', '87')):
        index_code = "899050"  # åŒ—è¯50
        index_name = "åŒ—è¯50"
        print(f"è¯†åˆ«ä¸ºåŒ—äº¬å¸‚åœºè‚¡ç¥¨ï¼Œä½¿ç”¨åŒ—è¯50 ({index_code})")
    else:
        index_code = "000001"  # é»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
        index_name = "ä¸Šè¯æŒ‡æ•°(é»˜è®¤)"
        print(f"æ— æ³•è¯†åˆ«å¸‚åœºç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•° ({index_code})")

    try:
        # è·å–å¤§ç›˜æŒ‡æ•°æ•°æ®
        index_data = ak.stock_zh_a_hist(symbol=index_code, period="daily",
                                      start_date=start_date, end_date=end_date, adjust="")

        if index_data.empty:
            print(f"âŒ è·å– {index_name} æ•°æ®å¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®")
            return pd.DataFrame(), "æœªçŸ¥æŒ‡æ•°"

        print(f"âœ… {index_name} æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(index_data)} æ¡è®°å½•")
        print(f"   æ—¶é—´èŒƒå›´: {index_data['æ—¥æœŸ'].min()} åˆ° {index_data['æ—¥æœŸ'].max()}")

        return index_data, index_name

    except Exception as e:
        print(f"âŒ è·å– {index_name} æ•°æ®æ—¶å‡ºé”™: {e}")
        return pd.DataFrame(), "æœªçŸ¥æŒ‡æ•°"

def get_industry_sector_data(stock_code: str, start_date: str, end_date: str) -> tuple:
    """
    è·å–è‚¡ç¥¨æ‰€å±è¡Œä¸šæ¿å—çš„æ—¥Kçº¿æ•°æ®å’Œæ¿å—åç§°ã€‚

    :param stock_code: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: tuple, (pd.DataFrame, str) - è¡Œä¸šæ¿å—æ—¥Kçº¿æ•°æ®å’Œæ¿å—åç§°
    """
    print(f"æ­£åœ¨è·å–è‚¡ç¥¨ {stock_code} æ‰€å±è¡Œä¸šæ¿å—æ•°æ®...")

    try:
        # æ­¥éª¤1: è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_info_df = ak.stock_individual_info_em(symbol=stock_code)

        if stock_info_df.empty:
            print("âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥")
            return pd.DataFrame(), "æœªçŸ¥æ¿å—"

        # ä»DataFrameä¸­æå–ä¿¡æ¯
        info_dict = dict(zip(stock_info_df['item'], stock_info_df['value']))

        stock_name = info_dict.get('è‚¡ç¥¨ç®€ç§°', 'æœªçŸ¥')
        industry_name = info_dict.get('è¡Œä¸š', 'æœªçŸ¥')

        print(f"âœ… è‚¡ç¥¨ä¿¡æ¯è·å–æˆåŠŸ: {stock_name}")
        print(f"   è¡Œä¸šåˆ†ç±»: {industry_name}")

        if industry_name == 'æœªçŸ¥' or not industry_name:
            print("âŒ æ— æ³•è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯")
            return pd.DataFrame(), "æœªçŸ¥æ¿å—"

        # æ­¥éª¤2: è·å–è¡Œä¸šæ¿å—æ•°æ®
        print(f"æ­£åœ¨è·å– '{industry_name}' è¡Œä¸šæ¿å—æ•°æ®...")
        industry_data = ak.stock_board_industry_hist_em(symbol=industry_name,
                                                       start_date=start_date,
                                                       end_date=end_date)

        if industry_data.empty:
            print(f"âŒ è·å– '{industry_name}' è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥")
            print("   å¯èƒ½åŸå› : è¡Œä¸šåç§°æ ¼å¼ä¸åŒ¹é…æˆ–æ•°æ®ä¸å¯ç”¨")
            return pd.DataFrame(), f"{industry_name}(æ•°æ®è·å–å¤±è´¥)"

        print(f"âœ… è¡Œä¸šæ¿å—æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(industry_data)} æ¡è®°å½•")
        print(f"   æ—¶é—´èŒƒå›´: {industry_data['æ—¥æœŸ'].min()} åˆ° {industry_data['æ—¥æœŸ'].max()}")

        return industry_data, industry_name

    except Exception as e:
        print(f"âŒ è·å–è¡Œä¸šæ¿å—æ•°æ®æ—¶å‡ºé”™: {e}")
        return pd.DataFrame(), "æœªçŸ¥æ¿å—"

def get_and_save_stock_data(stock: str, start_date: str, end_date: str, kline_days: int) -> str:
    """
    è·å–è‚¡ç¥¨çš„åˆ†æ—¶æˆäº¤æ•°æ®ã€æ—¥Kçº¿æ•°æ®ã€å¤§ç›˜æŒ‡æ•°æ•°æ®å’Œè¡Œä¸šæ¿å—æ•°æ®ï¼Œå¹¶ä¿å­˜åˆ°Excelæ–‡ä»¶ä¸­ã€‚

    :param stock: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '300680'
    :param start_date: str, åˆ†æ—¶æ•°æ®çš„èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, åˆ†æ—¶æ•°æ®çš„ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, æ—¥Kçº¿æ•°æ®çš„å¤©æ•°ï¼Œä¾‹å¦‚ 60
    :return: str, æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    try:
        # åˆ†æ—¶æ•°æ®ä½¿ç”¨ä¼ é€’çš„æ—¥æœŸèŒƒå›´ï¼ˆæ¥è‡ªdaysBeforeTodayï¼‰
        df_intraday, stock_name = get_intraday_data(stock=stock, start_date=start_date, end_date=end_date)

        # Kçº¿æ•°æ®ä½¿ç”¨åŸºäºkline_daysè®¡ç®—çš„æ—¥æœŸèŒƒå›´
        kline_start_date, kline_end_date = get_kline_date_range(kline_days)
        df_daily = get_daily_kline_data(symbol=stock, end_date=kline_end_date, kline_days=kline_days)

        # å¤§ç›˜æŒ‡æ•°æ•°æ®ä½¿ç”¨Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´
        df_market, market_index_name = get_market_index_data(stock_code=stock, start_date=kline_start_date, end_date=kline_end_date)

        # è¡Œä¸šæ¿å—æ•°æ®ä½¿ç”¨Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´
        df_industry, industry_sector_name = get_industry_sector_data(stock_code=stock, start_date=kline_start_date, end_date=kline_end_date)

        # ç”Ÿæˆä¸‰ä½éšæœºæ•°ï¼Œé¿å…æ–‡ä»¶åå†²çª
        random_suffix = str(random.randint(0, 999)).zfill(3)
        file_name = f"{stock}_{stock_name}_{start_date}_to_{end_date}_{random_suffix}.xlsx"

        # ä¿å­˜åˆ°Excelæ–‡ä»¶
        with pd.ExcelWriter(file_name) as writer:
            df_intraday.to_excel(writer, sheet_name='intraday', index=False)
            df_daily.to_excel(writer, sheet_name='daily', index=False)
            if not df_market.empty:
                df_market.to_excel(writer, sheet_name='market_index', index=False)
            if not df_industry.empty:
                df_industry.to_excel(writer, sheet_name='industry_sector', index=False)

        print(f"âœ… æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ° {file_name}")
        print(f"   åŒ…å«å·¥ä½œè¡¨: intraday, daily, market_index, industry_sector")
        return file_name, stock_name

    except Exception as e:
        print(f"âŒ å¤„ç†è‚¡ç¥¨ {stock} æ—¶å‡ºé”™: {e}")
        return None

def upload_file(file_path: str, api_key: str) -> str:
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°é€šä¹‰åƒé—®å¹³å°ã€‚
    
    :param file_path: str, æ–‡ä»¶è·¯å¾„
    :param api_key: str, API å¯†é’¥
    :return: str, æ–‡ä»¶ ID
    """
    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    file_object = client.files.create(file=Path(file_path), purpose="file-extract")
    print(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ–‡ä»¶ ID: {file_object.id}")
    return file_object.id

def chat_with_qwen(file_id: str, question: Any, api_key: str) -> str:
    """
    ä½¿ç”¨é€šä¹‰åƒé—®çš„ API è¿›è¡ŒèŠå¤©ï¼Œæ”¯æŒå­—å…¸æˆ–å­—ç¬¦ä¸²ç±»å‹çš„ questionã€‚
    
    :param file_id: str, æ–‡ä»¶ ID
    :param question: Any, ç”¨æˆ·æç¤ºæˆ–é—®é¢˜ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
    :param api_key: str, API å¯†é’¥
    :return: str, èŠå¤©ç»“æœ
    """
    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    # åˆå§‹åŒ– messages åˆ—è¡¨
    messages = [
        {'role': 'system', 'content': 'You are a helpful assistant.'},
        {'role': 'system', 'content': f'fileid://{file_id}'}
    ]

    # å¤„ç† question å‚æ•°
    if isinstance(question, dict):
        # å¦‚æœ question æ˜¯å­—å…¸ï¼Œå‡è®¾å®ƒåŒ…å« analysis_request
        analysis_request = question.get('analysis_request', {})

        # æ„é€ ç”¨æˆ·æ¶ˆæ¯å†…å®¹
        user_content = (
            f"{analysis_request.get('analysis_purpose', {}).get('description', '')}\n\n"
            f"intraday sheet: {analysis_request.get('data_description', {}).get('intraday_sheet', {}).get('description', '')}\n"
            f"å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('intraday_sheet', {}).get('fields', []))}\n"
            f"daily sheet: {analysis_request.get('data_description', {}).get('daily_sheet', {}).get('description', '')}\n"
            f"å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('daily_sheet', {}).get('fields', []))}\n\n"
            f"åˆ†ææ­¥éª¤:\n"
        )

        # æ·»åŠ åˆ†ææ­¥éª¤
        for step in analysis_request.get('analysis_steps', []):
            user_content += f"æ­¥éª¤ {step.get('step', '')}: {step.get('description', '')}\n"

        # æ·»åŠ è¾“å‡ºè¦æ±‚
        user_content += "\nè¾“å‡ºè¦æ±‚:\n"
        for req in analysis_request.get('output_requirements', []):
            user_content += f"{req.get('section', '')}. {req.get('title', '')}: {req.get('description', '')}\n"

        messages.append({'role': 'user', 'content': user_content})
    elif isinstance(question, str):
        # å¦‚æœ question æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆä¿æŒåå‘å…¼å®¹æ€§ï¼‰
        messages.append({'role': 'user', 'content': question})
    else:
        raise ValueError("question å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ç±»å‹")

    # è°ƒç”¨ API
    completion = client.chat.completions.create(
        model="qwen-long",
        messages=messages,
        stream=True,
        stream_options={"include_usage": True}
    )

    full_content = ""
    for chunk in completion:
        if chunk.choices and chunk.choices[0].delta.content:
            full_content += chunk.choices[0].delta.content
            print(".", end="", flush=True)

    return full_content

def select_prompt_by_model(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¹æ®å½“å‰è„šæœ¬ä½¿ç”¨çš„æ¨¡å‹æ™ºèƒ½é€‰æ‹©å¯¹åº”çš„prompté…ç½®ã€‚

    :param config: é…ç½®å­—å…¸
    :return: å¯¹åº”çš„prompté…ç½®
    """
    # å¯¹äºqwen-longï¼Œä½¿ç”¨åŸæœ‰çš„é€šç”¨promptï¼ˆåŒ…å«åˆ†æ—¶æ•°æ®å¤„ç†ï¼‰
    if 'prompt' in config:
        print("ğŸ¯ æ£€æµ‹åˆ°æ–‡ä»¶å¤„ç†æ¨¡å‹ä¸“ç”¨prompté…ç½®")
        return config['prompt']

    # å›é€€åˆ°é€šç”¨prompt
    print("â„¹ï¸ æœªæ‰¾åˆ°ä¸“ç”¨promptï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    return {}

def get_kline_date_range(kline_days: int) -> tuple:
    """
    æ ¹æ®kline_daysè®¡ç®—Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´ã€‚

    :param kline_days: int, Kçº¿æ•°æ®çš„å¤©æ•°
    :return: tuple, (start_date, end_date) æ ¼å¼ä¸ºYYYYMMDD
    """
    end_date = date.today().strftime('%Y%m%d')

    # è®¡ç®—Kçº¿æ•°æ®çš„å¼€å§‹æ—¥æœŸï¼ˆå¾€å‰kline_daysä¸ªäº¤æ˜“æ—¥ï¼‰
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    end_dt = pd.to_datetime(end_date)

    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ <= end_dtï¼Œé™åºæ’åºï¼Œå–å‰ kline_days ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
    trading_dates_filtered = calendar[calendar['trade_date'] <= end_dt]['trade_date'].sort_values(ascending=False).head(kline_days)

    if len(trading_dates_filtered) < kline_days:
        print(f"âš ï¸ è­¦å‘Š: ä»…æ‰¾åˆ° {len(trading_dates_filtered)} ä¸ªäº¤æ˜“æ—¥ï¼Œå¯ç”¨äº¤æ˜“æ—¥ä¸è¶³ {kline_days} å¤©")

    start_dt_kline = trading_dates_filtered.iloc[-1]  # æœ€æ—©çš„æ—¥æœŸåœ¨æœ€åé¢ï¼Œå› ä¸ºæ˜¯é™åº
    start_date = start_dt_kline.strftime('%Y%m%d')

    return start_date, end_date

def analyze_stocks(config_file: str = 'anylizeconfig.json', keys_file: str = 'keys.json'):
    """åˆ†æè‚¡ç¥¨çš„ä¸»å‡½æ•°"""
    # 1. è¯»å–é…ç½®
    config = load_config(config_file, keys_file)
    stocks = select_stocks(config)

    # åˆ†æ—¶æ•°æ®ä½¿ç”¨daysBeforeTodayè®¡ç®—æ—¥æœŸèŒƒå›´
    days_before = config['daysBeforeToday']
    intraday_start_date = (date.today() - timedelta(days=days_before)).strftime('%Y%m%d')
    intraday_end_date = date.today().strftime('%Y%m%d')
    print(f"ğŸ“… åˆ†æ—¶æ•°æ®æ—¥æœŸèŒƒå›´: {intraday_start_date} åˆ° {intraday_end_date}")

    # Kçº¿æ•°æ®ä½¿ç”¨kline_daysè®¡ç®—æ—¥æœŸèŒƒå›´
    kline_days = config.get('kline_days', 60)  # é»˜è®¤60å¤©
    kline_start_date, kline_end_date = get_kline_date_range(kline_days)
    print(f"ğŸ“… Kçº¿æ•°æ®æ—¥æœŸèŒƒå›´: {kline_start_date} åˆ° {kline_end_date} (å…±{kline_days}ä¸ªäº¤æ˜“æ—¥)")

    # æ™ºèƒ½é€‰æ‹©prompté…ç½®
    prompt_template = select_prompt_by_model(config)
    print(f"ğŸ¯ ä½¿ç”¨æ–‡ä»¶å¤„ç†æ¨¡å‹ä¸“ç”¨prompt (qwen-long)")

    api_key = config['api_key']  # ä» keys.json è¯»å– API å¯†é’¥
    email_sender = config['email_sender']  # ä»é…ç½®æ–‡ä»¶è¯»å–å‘ä»¶äººé‚®ç®±åœ°å€
    email_password = config['email_password']  # ä» keys.json è¯»å–å‘ä»¶äººé‚®ç®±å¯†ç 
    email_receivers = config['email_receivers']  # ä»é…ç½®æ–‡ä»¶è¯»å–æ”¶ä»¶äººé‚®ç®±åœ°å€

    # 2. å¾ªç¯å¤„ç†æ¯åªè‚¡ç¥¨
    total = len(stocks)
    for index, stock in enumerate(stocks):
        print(f"æ­£åœ¨å¤„ç†è‚¡ç¥¨: {stock} ({index+1}/{total})")
        file_path = None  # åˆå§‹åŒ–æ–‡ä»¶è·¯å¾„
        try:
            # è·å–æ•°æ®å¹¶ä¿å­˜åˆ°Excelæ–‡ä»¶
            result = get_and_save_stock_data(stock=stock, start_date=intraday_start_date, end_date=intraday_end_date, kline_days=kline_days)
            if result is None:
                print(f"è‚¡ç¥¨ {stock} è·å–æ•°æ®å¤±è´¥ï¼Œè·³è¿‡")
                continue
            file_path, stock_name = result

            # ä¸Šä¼ æ–‡ä»¶åˆ°å¹³å°
            file_id = upload_file(file_path=file_path, api_key=api_key)
            if file_id is None:
                print(f"è‚¡ç¥¨ {stock} çš„æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè·³è¿‡")
                continue

            # ä¸é€šä¹‰åƒé—®æ¨¡å‹äº¤äº’ï¼Œç›´æ¥ä¼ é€’å­—å…¸ç±»å‹çš„ prompt_template
            response = chat_with_qwen(file_id=file_id, question=prompt_template, api_key=api_key)
            if response:
                print(f"è‚¡ç¥¨ {stock} çš„åˆ†æç»“æœ: {response}\n")
            else:
                print(f"è‚¡ç¥¨ {stock} çš„èŠå¤©è¯·æ±‚å¤±è´¥ï¼\n")

            # å‘é€é‚®ä»¶å¹¶æ ¹æ®ç»“æœå†³å®šæ˜¯å¦åˆ é™¤æ–‡ä»¶
            print(f"è‚¡ç¥¨ {stock} å‡†å¤‡å‘é€é‚®ä»¶ \n")
            send_email(
                subject=f"è‚¡ç¥¨ {stock} åˆ†æç»“æœ",
                body=response,
                receivers=email_receivers,
                sender=email_sender,
                password=email_password,
                file_path=file_path  # ä¼ é€’æ–‡ä»¶è·¯å¾„ä»¥ä¾¿åˆ é™¤
            )

        except Exception as e:
            print(f"å¤„ç†è‚¡ç¥¨ {stock} æ—¶å‡ºé”™: {e}\n")

        if index < total - 1:
            for i in range(60):  # ç­‰å¾… 300 ç§’ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                print(".", end="", flush=True)
                t.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

# è¿è¡Œç¨‹åº
if __name__ == "__main__":
    analyze_stocks('anylizeconfig.json', 'keys.json')
