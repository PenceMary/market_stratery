import akshare as ak
import random
import json
import pandas as pd
from datetime import datetime, timedelta, date
from typing import List, Dict, Any
from openai import OpenAI
import os
from pathlib import Path
import smtplib
from email.mime.text import MIMEText
import time as t

def send_email(subject: str, body: str, receivers: List[str], sender: str, password: str, file_path: str = None) -> bool:
    """å‘é€é‚®ä»¶å¹¶è¿”å›æ˜¯å¦æˆåŠŸ"""
    # åˆ›å»ºæ–‡æœ¬é‚®ä»¶
    msg = MIMEText(body, 'plain', 'utf-8')
    msg['From'] = sender  # å‘ä»¶äºº
    msg['To'] = ', '.join(receivers)  # å°†æ”¶ä»¶äººåˆ—è¡¨è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
    msg['Subject'] = subject

    # SMTPæœåŠ¡å™¨è®¾ç½®
    smtp_server = 'applesmtp.163.com'
    smtp_port = 465

    # ç™»å½•å‡­è¯ï¼ˆä½¿ç”¨æˆæƒç ï¼‰
    username = sender

    # å‘é€é‚®ä»¶
    try:
        server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        server.login(username, password)
        server.sendmail(sender, receivers, msg.as_string())
        server.quit()
        print("é‚®ä»¶å‘é€æˆåŠŸï¼")
        # å¦‚æœé‚®ä»¶å‘é€æˆåŠŸä¸”æä¾›äº†æ–‡ä»¶è·¯å¾„ï¼Œåˆ™åˆ é™¤æœ¬åœ°æ–‡ä»¶
        if file_path and os.path.exists(file_path):
            #os.remove(file_path)
            print(f"æœ¬åœ°æ–‡ä»¶ {file_path} å·²åˆ é™¤")
        return True
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼š{e}")
        return False

def load_config(config_file: str, keys_file: str) -> Dict[str, Any]:
    """è¯»å– JSON é…ç½®æ–‡ä»¶å¹¶è¿”å›é…ç½®å­—å…¸"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        with open(keys_file, 'r', encoding='utf-8') as f:
            keys = json.load(f)
        config.update(keys)  # åˆå¹¶ keys.json ä¸­çš„é…ç½®
        return config
    except Exception as e:
        raise Exception(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

def select_stocks(config: Dict[str, Any]) -> List[str]:
    """æ ¹æ®é…ç½®æ–‡ä»¶é€‰æ‹©è‚¡ç¥¨"""
    if config['stock_selection'] == 'specified':
        return config['specified_stocks']
    elif config['stock_selection'] == 'random':
        all_stocks = ak.stock_zh_a_spot_em()['ä»£ç '].tolist()
        return random.sample(all_stocks, min(config['random_stock_count'], len(all_stocks)))
    else:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­çš„ 'stock_selection' å¿…é¡»æ˜¯ 'specified' æˆ– 'random'")

def get_trading_dates(start_date: str, end_date: str) -> List[str]:
    """
    è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„äº¤æ˜“æ—¥åˆ—è¡¨ã€‚
    
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: list, äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œæ ¼å¼ä¸º 'YYYYMMDD'
    """
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    start_date_dt = pd.to_datetime(start_date)
    end_date_dt = pd.to_datetime(end_date)
    trading_dates = calendar[(calendar['trade_date'] >= start_date_dt) & 
                             (calendar['trade_date'] <= end_date_dt)]['trade_date']
    return trading_dates.dt.strftime('%Y%m%d').tolist()

def get_intraday_data(stock: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„åˆ†æ—¶æˆäº¤æ•°æ®ã€‚
    
    :param stock: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: pd.DataFrame, åˆ†æ—¶æˆäº¤æ•°æ®ï¼Œsymbol å’Œ name åˆ—å·²åˆ é™¤
    """
    # æ ¹æ®è‚¡ç¥¨ä»£ç å‰ç¼€è°ƒæ•´åˆ†é’Ÿçº¿ä»£ç 
    if stock.startswith('688'):
        minute_code = f"sh{stock}"
    elif stock.startswith(('83', '43', '87')):
        minute_code = f"bj{stock}"
    elif stock.startswith('60'):
        minute_code = f"sh{stock}"
    elif stock.startswith(('00', '30')):
        minute_code = f"sz{stock}"
    else:
        minute_code = stock
    print(f"minute_code: {minute_code}")

    trading_dates = get_trading_dates(start_date, end_date)
    stock_data_list = []
    for date in trading_dates:
        max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        for attempt in range(max_retries):
            try:
                daily_data = ak.stock_intraday_sina(symbol=minute_code, date=date)
                if not daily_data.empty:
                    daily_data['ticktime'] = pd.to_datetime(date + ' ' + daily_data['ticktime'])
                    stock_data_list.append(daily_data)
                    print(f"æˆåŠŸè·å– {minute_code} åœ¨ {date} çš„æ•°æ®")
                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œç­‰å¾… 2 åˆ†é’Ÿ
                    if date != trading_dates[-1]:
                        print("ç¨ç­‰ä¸€ä¸‹...")
                        for _ in range(random.randint(1, 10)):  # ç­‰å¾…éšæœºç§’æ•°ï¼Œæ¯ç§’æ‰“å°ä¸€ä¸ªâ€œ.â€
                            print(".", end="", flush=True)
                            t.sleep(1)
                        print()  # æ¢è¡Œ
                    break  # æˆåŠŸè·å–æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
            except Exception as e:
                print(f"è·å–è‚¡ç¥¨ {minute_code} åœ¨ {date} çš„æ•°æ®æ—¶å‡ºé”™: {e}")
                if attempt < max_retries - 1:  # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…é‡è¯•
                    print("ç­‰å¾…20ç§’åé‡è¯•...")
                    for _ in range(10):  # ç­‰å¾…600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰ï¼Œæ¯2ç§’æ‰“å°ä¸€ä¸ªâ€œ.â€
                        print(".", end="", flush=True)
                        t.sleep(2)
                    print()  # æ¢è¡Œ
                else:
                    print(f"è‚¡ç¥¨ {minute_code} åœ¨ {date} çš„æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡")
                    break  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³å‡ºå¾ªç¯

    if not stock_data_list:
        raise ValueError(f"æ— æ³•è·å– {minute_code} çš„é€ç¬”æˆäº¤æ•°æ®")
    stock_name = daily_data['name'][0]
    all_data = pd.concat(stock_data_list)
    all_data = all_data.sort_values('ticktime').reset_index(drop=True)
    all_data = all_data.drop(columns=['symbol', 'name'], errors='ignore')
    return all_data, stock_name

def get_daily_kline_data(symbol: str, end_date: str, kline_days: int) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨æœ€è¿‘ kline_days ä¸ªäº¤æ˜“æ—¥çš„æ—¥Kçº¿æ•°æ®ã€‚
    
    :param symbol: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '300680'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, éœ€è¦çš„äº¤æ˜“æ—¥æ•°é‡ï¼Œä¾‹å¦‚ 60
    :return: pd.DataFrame, æ—¥Kçº¿æ•°æ®
    """
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    end_dt = pd.to_datetime(end_date)
    
    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ <= end_dtï¼Œé™åºæ’åºï¼Œå–å‰ kline_days ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
    trading_dates_filtered = calendar[calendar['trade_date'] <= end_dt]['trade_date'].sort_values(ascending=False).head(kline_days)
    
    if len(trading_dates_filtered) < kline_days:
        print(f"Warning: Only {len(trading_dates_filtered)} trading days available up to {end_date}")
    
    start_dt_kline = trading_dates_filtered.iloc[-1]  # æœ€æ—©çš„æ—¥æœŸåœ¨æœ€åé¢ï¼Œå› ä¸ºæ˜¯é™åº
    end_dt_kline = trading_dates_filtered.iloc[0]  # æœ€æ™šçš„æ—¥æœŸåœ¨æœ€å‰é¢
    
    start_date_kline = start_dt_kline.strftime('%Y%m%d')
    end_date_kline = end_dt_kline.strftime('%Y%m%d')
    
    # è·å–æ—¥Kçº¿æ•°æ®
    stock_data = ak.stock_zh_a_hist(symbol=symbol, period="daily", start_date=start_date_kline, end_date=end_date_kline, adjust="")
    return stock_data

def get_market_index_data(stock_code: str, start_date: str, end_date: str, kline_days: int = 30) -> tuple:
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç è·å–å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°æ—¥Kçº¿æ•°æ®å’ŒæŒ‡æ•°åç§°ã€‚

    :param stock_code: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, è·å–çš„Kçº¿å¤©æ•°ï¼Œé»˜è®¤30å¤©
    :return: tuple, (pd.DataFrame, str) - å¤§ç›˜æŒ‡æ•°æ—¥Kçº¿æ•°æ®å’ŒæŒ‡æ•°åç§°
    """
    print(f"æ­£åœ¨è·å–è‚¡ç¥¨ {stock_code} å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°æ•°æ®...")

    # æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šå¤§ç›˜æŒ‡æ•°
    if stock_code.startswith(('60', '688')):
        index_code = "000001"  # ä¸Šè¯æŒ‡æ•°
        index_name = "ä¸Šè¯æŒ‡æ•°"
        print(f"è¯†åˆ«ä¸ºä¸Šæµ·å¸‚åœºè‚¡ç¥¨ï¼Œä½¿ç”¨ä¸Šè¯æŒ‡æ•° ({index_code})")
    elif stock_code.startswith(('00', '30')):
        index_code = "399001"  # æ·±åœ³æˆæŒ‡
        index_name = "æ·±åœ³æˆæŒ‡"
        print(f"è¯†åˆ«ä¸ºæ·±åœ³å¸‚åœºè‚¡ç¥¨ï¼Œä½¿ç”¨æ·±åœ³æˆæŒ‡ ({index_code})")
    elif stock_code.startswith(('83', '43', '87')):
        index_code = "899050"  # åŒ—è¯50
        index_name = "åŒ—è¯50"
        print(f"è¯†åˆ«ä¸ºåŒ—äº¬å¸‚åœºè‚¡ç¥¨ï¼Œä½¿ç”¨åŒ—è¯50 ({index_code})")
    else:
        index_code = "000001"  # é»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
        index_name = "ä¸Šè¯æŒ‡æ•°(é»˜è®¤)"
        print(f"æ— æ³•è¯†åˆ«å¸‚åœºç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•° ({index_code})")

    try:
        # ç‰¹æ®Šå¤„ç†ä¸Šè¯æŒ‡æ•°ï¼Œé¿å…ä¸å¹³å®‰é“¶è¡Œä»£ç å†²çª
        if index_code == "000001":
            # ä½¿ç”¨æŒ‡æ•°ä¸“ç”¨APIè·å–ä¸Šè¯æŒ‡æ•°æ•°æ®
            index_data = ak.stock_zh_index_daily(symbol="sh000001")
            # è·å–æœ€è¿‘ kline_days å¤©çš„ä¸Šè¯æŒ‡æ•°æ•°æ®
            index_data = index_data.tail(kline_days)
            # å°†è‹±æ–‡åˆ—åè½¬æ¢ä¸ºä¸­æ–‡åˆ—åï¼Œä¸å…¶ä»–æŒ‡æ•°ä¿æŒä¸€è‡´
            index_data = index_data.rename(columns={
                'date': 'æ—¥æœŸ',
                'open': 'å¼€ç›˜',
                'high': 'æœ€é«˜',
                'low': 'æœ€ä½',
                'close': 'æ”¶ç›˜',
                'volume': 'æˆäº¤é‡'
            })
            print(f"âœ… ä½¿ç”¨æŒ‡æ•°ä¸“ç”¨APIè·å– {index_name} æ•°æ®æˆåŠŸ")
        else:
            # å…¶ä»–æŒ‡æ•°ä½¿ç”¨åŸæœ‰çš„æ–¹æ³•
            index_data = ak.stock_zh_a_hist(symbol=index_code, period="daily",
                                          start_date=start_date, end_date=end_date, adjust="")

        if index_data.empty:
            print(f"âŒ è·å– {index_name} æ•°æ®å¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®")
            return pd.DataFrame(), "æœªçŸ¥æŒ‡æ•°"

        print(f"âœ… {index_name} æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(index_data)} æ¡è®°å½•")
        if not index_data.empty:
            print(f"   æ—¶é—´èŒƒå›´: {index_data['æ—¥æœŸ'].min()} åˆ° {index_data['æ—¥æœŸ'].max()}")

        return index_data, index_name

    except Exception as e:
        print(f"âŒ è·å– {index_name} æ•°æ®æ—¶å‡ºé”™: {e}")
        return pd.DataFrame(), "æœªçŸ¥æŒ‡æ•°"

def get_industry_sector_data(stock_code: str, start_date: str, end_date: str) -> tuple:
    """
    è·å–è‚¡ç¥¨æ‰€å±è¡Œä¸šæ¿å—çš„æ—¥Kçº¿æ•°æ®å’Œæ¿å—åç§°ã€‚

    :param stock_code: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: tuple, (pd.DataFrame, str) - è¡Œä¸šæ¿å—æ—¥Kçº¿æ•°æ®å’Œæ¿å—åç§°
    """
    print(f"æ­£åœ¨è·å–è‚¡ç¥¨ {stock_code} æ‰€å±è¡Œä¸šæ¿å—æ•°æ®...")

    try:
        # æ­¥éª¤1: è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_info_df = ak.stock_individual_info_em(symbol=stock_code)

        if stock_info_df.empty:
            print("âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥")
            return pd.DataFrame(), "æœªçŸ¥æ¿å—"

        # ä»DataFrameä¸­æå–ä¿¡æ¯
        info_dict = dict(zip(stock_info_df['item'], stock_info_df['value']))

        stock_name = info_dict.get('è‚¡ç¥¨ç®€ç§°', 'æœªçŸ¥')
        industry_name = info_dict.get('è¡Œä¸š', 'æœªçŸ¥')

        print(f"âœ… è‚¡ç¥¨ä¿¡æ¯è·å–æˆåŠŸ: {stock_name}")
        print(f"   è¡Œä¸šåˆ†ç±»: {industry_name}")

        if industry_name == 'æœªçŸ¥' or not industry_name:
            print("âŒ æ— æ³•è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯")
            return pd.DataFrame(), "æœªçŸ¥æ¿å—"

        # æ­¥éª¤2: è·å–è¡Œä¸šæ¿å—æ•°æ®
        print(f"æ­£åœ¨è·å– '{industry_name}' è¡Œä¸šæ¿å—æ•°æ®...")
        industry_data = ak.stock_board_industry_hist_em(symbol=industry_name,
                                                       start_date=start_date,
                                                       end_date=end_date)

        if industry_data.empty:
            print(f"âŒ è·å– '{industry_name}' è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥")
            print("   å¯èƒ½åŸå› : è¡Œä¸šåç§°æ ¼å¼ä¸åŒ¹é…æˆ–æ•°æ®ä¸å¯ç”¨")
            return pd.DataFrame(), f"{industry_name}(æ•°æ®è·å–å¤±è´¥)"

        print(f"âœ… è¡Œä¸šæ¿å—æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(industry_data)} æ¡è®°å½•")
        print(f"   æ—¶é—´èŒƒå›´: {industry_data['æ—¥æœŸ'].min()} åˆ° {industry_data['æ—¥æœŸ'].max()}")

        return industry_data, industry_name

    except Exception as e:
        print(f"âŒ è·å–è¡Œä¸šæ¿å—æ•°æ®æ—¶å‡ºé”™: {e}")
        return pd.DataFrame(), "æœªçŸ¥æ¿å—"

def get_and_save_stock_data(stock: str, start_date: str, end_date: str, kline_days: int) -> tuple:
    """
    è·å–è‚¡ç¥¨çš„åˆ†æ—¶æˆäº¤æ•°æ®ã€æ—¥Kçº¿æ•°æ®ã€å¤§ç›˜æŒ‡æ•°æ•°æ®å’Œè¡Œä¸šæ¿å—æ•°æ®ï¼Œå¹¶ä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­ã€‚

    :param stock: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '300680'
    :param start_date: str, åˆ†æ—¶æ•°æ®çš„èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, åˆ†æ—¶æ•°æ®çš„ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, æ—¥Kçº¿æ•°æ®çš„å¤©æ•°ï¼Œä¾‹å¦‚ 60
    :return: tuple, (file_paths, stock_name) æ–‡ä»¶è·¯å¾„å­—å…¸å’Œè‚¡ç¥¨åç§°ï¼Œå¤±è´¥è¿”å› (None, None)
    """
    try:
        # åˆ†æ—¶æ•°æ®ä½¿ç”¨ä¼ é€’çš„æ—¥æœŸèŒƒå›´ï¼ˆæ¥è‡ªdaysBeforeTodayï¼‰
        df_intraday, stock_name = get_intraday_data(stock=stock, start_date=start_date, end_date=end_date)

        # Kçº¿æ•°æ®ä½¿ç”¨åŸºäºkline_daysè®¡ç®—çš„æ—¥æœŸèŒƒå›´
        kline_start_date, kline_end_date = get_kline_date_range(kline_days)
        df_daily = get_daily_kline_data(symbol=stock, end_date=kline_end_date, kline_days=kline_days)

        # å¤§ç›˜æŒ‡æ•°æ•°æ®ä½¿ç”¨Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´
        df_market, market_index_name = get_market_index_data(stock_code=stock, start_date=kline_start_date, end_date=kline_end_date, kline_days=kline_days)

        # è¡Œä¸šæ¿å—æ•°æ®ä½¿ç”¨Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´
        df_industry, industry_sector_name = get_industry_sector_data(stock_code=stock, start_date=kline_start_date, end_date=kline_end_date)

        # ç”Ÿæˆä¸‰ä½éšæœºæ•°ï¼Œé¿å…æ–‡ä»¶åå†²çª
        random_suffix = str(random.randint(0, 999)).zfill(3)
        base_filename = f"{stock}_{stock_name}_{start_date}_to_{end_date}_{random_suffix}"

        # ä¿å­˜åˆ°CSVæ–‡ä»¶ - åˆ›å»ºå¤šä¸ªæ–‡ä»¶
        file_paths = {}

        # ä¿å­˜åˆ†æ—¶æ•°æ®
        intraday_file = f"{base_filename}_intraday.csv"
        df_intraday.to_csv(intraday_file, index=False, encoding='utf-8-sig')
        file_paths['intraday'] = intraday_file
        print(f"âœ… åˆ†æ—¶æ•°æ®å·²ä¿å­˜åˆ° {intraday_file}")

        # ä¿å­˜æ—¥Kçº¿æ•°æ®
        daily_file = f"{base_filename}_daily.csv"
        df_daily.to_csv(daily_file, index=False, encoding='utf-8-sig')
        file_paths['daily'] = daily_file
        print(f"âœ… æ—¥Kçº¿æ•°æ®å·²ä¿å­˜åˆ° {daily_file}")

        # ä¿å­˜å¤§ç›˜æŒ‡æ•°æ•°æ®
        if not df_market.empty:
            market_file = f"{base_filename}_market_index.csv"
            df_market.to_csv(market_file, index=False, encoding='utf-8-sig')
            file_paths['market_index'] = market_file
            print(f"âœ… å¤§ç›˜æŒ‡æ•°æ•°æ®å·²ä¿å­˜åˆ° {market_file}")

        # ä¿å­˜è¡Œä¸šæ¿å—æ•°æ®
        if not df_industry.empty:
            industry_file = f"{base_filename}_industry_sector.csv"
            df_industry.to_csv(industry_file, index=False, encoding='utf-8-sig')
            file_paths['industry_sector'] = industry_file
            print(f"âœ… è¡Œä¸šæ¿å—æ•°æ®å·²ä¿å­˜åˆ° {industry_file}")

        # åˆ›å»ºä¸€ä¸ªåˆå¹¶çš„CSVæ–‡ä»¶ç”¨äºä¸Šä¼ åˆ°é€šä¹‰åƒé—®ï¼ˆåŒ…å«æ‰€æœ‰æ•°æ®ï¼‰
        main_file = f"{base_filename}_complete.csv"
        with open(main_file, 'w', encoding='utf-8-sig', newline='') as f:
            # å†™å…¥æ ‡é¢˜ä¿¡æ¯
            f.write(f"è‚¡ç¥¨ä»£ç : {stock}\n")
            f.write(f"è‚¡ç¥¨åç§°: {stock_name}\n")
            f.write(f"æ•°æ®æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}\n")
            f.write(f"Kçº¿æ•°æ®å¤©æ•°: {kline_days}\n\n")

            # å†™å…¥åˆ†æ—¶æ•°æ®
            f.write("=== åˆ†æ—¶æˆäº¤æ•°æ® ===\n")
            df_intraday.to_csv(f, index=False)
            f.write("\n\n")

            # å†™å…¥æ—¥Kçº¿æ•°æ®
            f.write("=== æ—¥Kçº¿æ•°æ® ===\n")
            df_daily.to_csv(f, index=False)
            f.write("\n\n")

            # å†™å…¥å¤§ç›˜æŒ‡æ•°æ•°æ®
            if not df_market.empty:
                f.write("=== å¤§ç›˜æŒ‡æ•°æ•°æ® ===\n")
                df_market.to_csv(f, index=False)
                f.write("\n\n")

            # å†™å…¥è¡Œä¸šæ¿å—æ•°æ®
            if not df_industry.empty:
                f.write("=== è¡Œä¸šæ¿å—æ•°æ® ===\n")
                df_industry.to_csv(f, index=False)
                f.write("\n\n")

        file_paths['complete'] = main_file
        print(f"âœ… åˆå¹¶æ•°æ®æ–‡ä»¶å·²ä¿å­˜åˆ° {main_file} (ç”¨äºä¸Šä¼ )")
        print(f"âœ… æ‰€æœ‰æ•°æ®å·²ä¿å­˜ä¸ºCSVæ ¼å¼ï¼Œå…± {len(file_paths)} ä¸ªæ–‡ä»¶")
        print(f"   æ–‡ä»¶åˆ—è¡¨: {', '.join(file_paths.keys())}")

        return file_paths, stock_name

    except Exception as e:
        print(f"âŒ å¤„ç†è‚¡ç¥¨ {stock} æ—¶å‡ºé”™: {e}")
        return None, None

def upload_file(file_path: str, api_key: str) -> str:
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°é€šä¹‰åƒé—®å¹³å°ã€‚
    
    :param file_path: str, æ–‡ä»¶è·¯å¾„
    :param api_key: str, API å¯†é’¥
    :return: str, æ–‡ä»¶ ID
    """
    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    file_object = client.files.create(file=Path(file_path), purpose="file-extract")
    print(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ–‡ä»¶ ID: {file_object.id}")
    return file_object.id

def chat_with_qwen(file_id: str, question: Any, api_key: str, days_before_today: int = 7, kline_days: int = 30) -> str:
    """
    ä½¿ç”¨é€šä¹‰åƒé—®çš„ API è¿›è¡ŒèŠå¤©ï¼Œæ”¯æŒå­—å…¸æˆ–å­—ç¬¦ä¸²ç±»å‹çš„ questionã€‚

    :param file_id: str, æ–‡ä»¶ ID
    :param question: Any, ç”¨æˆ·æç¤ºæˆ–é—®é¢˜ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
    :param api_key: str, API å¯†é’¥
    :param days_before_today: int, åˆ†æ—¶æ•°æ®çš„å¤©æ•°ï¼Œé»˜è®¤7å¤©
    :param kline_days: int, Kçº¿æ•°æ®çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©
    :return: str, èŠå¤©ç»“æœ
    """
    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    # åˆå§‹åŒ– messages åˆ—è¡¨
    messages = [
        {'role': 'system', 'content': 'You are a helpful assistant.'},
        {'role': 'system', 'content': f'fileid://{file_id}'}
    ]

    # å¤„ç† question å‚æ•°
    if isinstance(question, dict):
        # å¦‚æœ question æ˜¯å­—å…¸ï¼Œå‡è®¾å®ƒåŒ…å« analysis_request
        analysis_request = question.get('analysis_request', {})

        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œå…¶æ¬¡ä»questionä¸­è·å–
        days_before_today = days_before_today
        kline_days = kline_days

        # æ„é€ ç”¨æˆ·æ¶ˆæ¯å†…å®¹ - å¢å¼ºçš„åˆ†ææè¿°
        user_content = (
            f"{analysis_request.get('analysis_purpose', {}).get('description', '')}\n\n"
            f"ğŸ“Š æ•°æ®æ—¶é—´èŒƒå›´è¯´æ˜ï¼š\n"
            f"- åˆ†æ—¶æˆäº¤æ•°æ®ï¼šåŒ…å«æœ€è¿‘ {days_before_today} ä¸ªäº¤æ˜“æ—¥çš„æ—¥å†…åˆ†æ—¶æ•°æ®\n"
            f"- æ—¥Kçº¿æ•°æ®ï¼šåŒ…å«æœ€è¿‘ {kline_days} ä¸ªäº¤æ˜“æ—¥çš„Kçº¿æ•°æ®\n"
            f"- å¤§ç›˜æŒ‡æ•°æ•°æ®ï¼šå¯¹åº”è‚¡ç¥¨æ‰€å±å¸‚åœºçš„æŒ‡æ•°ï¼Œæ—¶é—´èŒƒå›´ä¸Kçº¿æ•°æ®ä¸€è‡´\n"
            f"- è¡Œä¸šæ¿å—æ•°æ®ï¼šè‚¡ç¥¨æ‰€å±è¡Œä¸šçš„æ¿å—æŒ‡æ•°ï¼Œæ—¶é—´èŒƒå›´ä¸Kçº¿æ•°æ®ä¸€è‡´\n\n"
            f"ğŸ” æ•°æ®å·¥ä½œè¡¨è¯¦ç»†è¯´æ˜ï¼š\n"
            f"â€¢ intraday sheet: {analysis_request.get('data_description', {}).get('intraday_sheet', {}).get('description', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('intraday_sheet', {}).get('fields', []))}\n\n"
            f"â€¢ daily sheet: {analysis_request.get('data_description', {}).get('daily_sheet', {}).get('description', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('daily_sheet', {}).get('fields', []))}\n\n"
            f"â€¢ industry_sector sheet: {analysis_request.get('data_description', {}).get('industry_sector_sheet', {}).get('description', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('industry_sector_sheet', {}).get('fields', []))}\n\n"
            f"â€¢ market_index sheet: {analysis_request.get('data_description', {}).get('market_index_sheet', {}).get('description', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('market_index_sheet', {}).get('fields', []))}\n\n"
            f"ğŸ“ˆ å¤šæ—¥æ•°æ®åˆ†æè¦æ±‚ï¼š\n"
            f"è¯·å¯¹æä¾›çš„å¤šæ—¥åˆ†æ—¶æ•°æ®è¿›è¡Œé€æ—¥æ·±åº¦åˆ†æï¼ˆæŒ‰æ—¶é—´é¡ºåºç”±è¿œåŠè¿‘ï¼‰ï¼Œé‡ç‚¹å…³æ³¨ï¼š\n"
            f"1. å„äº¤æ˜“æ—¥çš„èµ„é‡‘åŠ¨å‘å˜åŒ–è¶‹åŠ¿\n"
            f"2. ä»·æ ¼è¡Œä¸ºçš„æ¼”å˜è§„å¾‹\n"
            f"3. ä¸å¤§ç›˜æŒ‡æ•°å’Œè¡Œä¸šæ¿å—çš„ç›¸å¯¹å¼ºå¼±å…³ç³»\n"
            f"4. æˆäº¤é‡é…åˆå…³ç³»çš„å˜åŒ–\n"
            f"5. ä¸»åŠ›èµ„é‡‘æ„å›¾çš„è½¬å˜\n\n"
            f"ğŸ”¬ åˆ†ææ­¥éª¤ï¼ˆåº”ç”¨äºæ¯ä¸€å¤©çš„åˆ†æ—¶æ•°æ®ï¼‰ï¼š\n"
        )

        # æ·»åŠ åˆ†ææ­¥éª¤ - é’ˆå¯¹å¤šæ—¥æ•°æ®è¿›è¡Œé€æ—¥åˆ†æ
        for step in analysis_request.get('analysis_steps', []):
            user_content += f"æ­¥éª¤ {step.get('step', '')}: {step.get('description', '')}\n"

        # æ·»åŠ å¢å¼ºçš„è¾“å‡ºè¦æ±‚ - é‡ç‚¹å¼ºè°ƒæœªæ¥èµ°åŠ¿é¢„æµ‹
        user_content += "\nğŸ“‹ è¾“å‡ºè¦æ±‚ï¼ˆåŸºäºå¤šæ—¥æ•°æ®åˆ†æï¼‰ï¼š\n"
        for req in analysis_request.get('output_requirements', []):
            user_content += f"{req.get('section', '')}. {req.get('title', '')}: {req.get('description', '')}\n"

        # æ·»åŠ ä¸“é—¨çš„æœªæ¥èµ°åŠ¿é¢„æµ‹è¦æ±‚
        user_content += "\nğŸ¯ æœªæ¥èµ°åŠ¿é¢„æµ‹è¦æ±‚ï¼š\n"
        user_content += "åŸºäºä¸Šè¿°å¤šæ—¥æ•°æ®çš„æ·±åº¦åˆ†æï¼Œè¯·æä¾›æœªæ¥3-5ä¸ªäº¤æ˜“æ—¥çš„èµ°åŠ¿é¢„æœŸï¼š\n"
        user_content += "1. çŸ­æœŸä»·æ ¼ç›®æ ‡åŒºé—´é¢„æµ‹\n"
        user_content += "2. å…³é”®æ”¯æ’‘é˜»åŠ›ä½è¯†åˆ«\n"
        user_content += "3. æˆäº¤é‡å˜åŒ–è¶‹åŠ¿é¢„åˆ¤\n"
        user_content += "4. èµ„é‡‘åŠ¨å‘æŒç»­æ€§åˆ†æ\n"
        user_content += "5. é£é™©æç¤ºå’Œåº”å¯¹ç­–ç•¥\n"
        user_content += "6. æœ€ä½³ä¹°å…¥/å–å‡ºæ—¶æœºå»ºè®®\n\n"

        messages.append({'role': 'user', 'content': user_content})
    elif isinstance(question, str):
        # å¦‚æœ question æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆä¿æŒåå‘å…¼å®¹æ€§ï¼‰
        messages.append({'role': 'user', 'content': question})
    else:
        raise ValueError("question å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ç±»å‹")

    print(messages)

    # è°ƒç”¨ API
    completion = client.chat.completions.create(
        model="qwen-long",
        messages=messages,
        stream=True,
        stream_options={"include_usage": True}
    )

    full_content = ""
    for chunk in completion:
        if chunk.choices and chunk.choices[0].delta.content:
            full_content += chunk.choices[0].delta.content
            print(".", end="", flush=True)

    return full_content

def select_prompt_by_model(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¹æ®å½“å‰è„šæœ¬ä½¿ç”¨çš„æ¨¡å‹æ™ºèƒ½é€‰æ‹©å¯¹åº”çš„prompté…ç½®ã€‚

    :param config: é…ç½®å­—å…¸
    :return: å¯¹åº”çš„prompté…ç½®
    """
    # å¯¹äºqwen-longï¼Œä½¿ç”¨åŸæœ‰çš„é€šç”¨promptï¼ˆåŒ…å«åˆ†æ—¶æ•°æ®å¤„ç†ï¼‰
    if 'prompt' in config:
        print("ğŸ¯ æ£€æµ‹åˆ°æ–‡ä»¶å¤„ç†æ¨¡å‹ä¸“ç”¨prompté…ç½®")
        return config['prompt']

    # å›é€€åˆ°é€šç”¨prompt
    print("â„¹ï¸ æœªæ‰¾åˆ°ä¸“ç”¨promptï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    return {}

def get_kline_date_range(kline_days: int) -> tuple:
    """
    æ ¹æ®kline_daysè®¡ç®—Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´ã€‚

    :param kline_days: int, Kçº¿æ•°æ®çš„å¤©æ•°
    :return: tuple, (start_date, end_date) æ ¼å¼ä¸ºYYYYMMDD
    """
    end_date = date.today().strftime('%Y%m%d')

    # è®¡ç®—Kçº¿æ•°æ®çš„å¼€å§‹æ—¥æœŸï¼ˆå¾€å‰kline_daysä¸ªäº¤æ˜“æ—¥ï¼‰
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    end_dt = pd.to_datetime(end_date)

    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ <= end_dtï¼Œé™åºæ’åºï¼Œå–å‰ kline_days ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
    trading_dates_filtered = calendar[calendar['trade_date'] <= end_dt]['trade_date'].sort_values(ascending=False).head(kline_days)

    if len(trading_dates_filtered) < kline_days:
        print(f"âš ï¸ è­¦å‘Š: ä»…æ‰¾åˆ° {len(trading_dates_filtered)} ä¸ªäº¤æ˜“æ—¥ï¼Œå¯ç”¨äº¤æ˜“æ—¥ä¸è¶³ {kline_days} å¤©")

    start_dt_kline = trading_dates_filtered.iloc[-1]  # æœ€æ—©çš„æ—¥æœŸåœ¨æœ€åé¢ï¼Œå› ä¸ºæ˜¯é™åº
    start_date = start_dt_kline.strftime('%Y%m%d')

    return start_date, end_date

def analyze_stocks(config_file: str = 'anylizeconfig.json', keys_file: str = 'keys.json'):
    """åˆ†æè‚¡ç¥¨çš„ä¸»å‡½æ•°"""
    # 1. è¯»å–é…ç½®
    config = load_config(config_file, keys_file)
    stocks = select_stocks(config)

    # åˆ†æ—¶æ•°æ®ä½¿ç”¨daysBeforeTodayè®¡ç®—æ—¥æœŸèŒƒå›´
    days_before = config['daysBeforeToday']
    intraday_start_date = (date.today() - timedelta(days=days_before)).strftime('%Y%m%d')
    intraday_end_date = date.today().strftime('%Y%m%d')
    print(f"ğŸ“… åˆ†æ—¶æ•°æ®æ—¥æœŸèŒƒå›´: {intraday_start_date} åˆ° {intraday_end_date}")

    # Kçº¿æ•°æ®ä½¿ç”¨kline_daysè®¡ç®—æ—¥æœŸèŒƒå›´
    kline_days = config.get('kline_days', 60)  # é»˜è®¤60å¤©
    kline_start_date, kline_end_date = get_kline_date_range(kline_days)
    print(f"ğŸ“… Kçº¿æ•°æ®æ—¥æœŸèŒƒå›´: {kline_start_date} åˆ° {kline_end_date} (å…±{kline_days}ä¸ªäº¤æ˜“æ—¥)")

    # æ™ºèƒ½é€‰æ‹©prompté…ç½®
    prompt_template = select_prompt_by_model(config)
    print(f"ğŸ¯ ä½¿ç”¨æ–‡ä»¶å¤„ç†æ¨¡å‹ä¸“ç”¨prompt (qwen-long)")

    api_key = config['api_key']  # ä» keys.json è¯»å– API å¯†é’¥
    email_sender = config['email_sender']  # ä»é…ç½®æ–‡ä»¶è¯»å–å‘ä»¶äººé‚®ç®±åœ°å€
    email_password = config['email_password']  # ä» keys.json è¯»å–å‘ä»¶äººé‚®ç®±å¯†ç 
    email_receivers = config['email_receivers']  # ä»é…ç½®æ–‡ä»¶è¯»å–æ”¶ä»¶äººé‚®ç®±åœ°å€

    # 2. å¾ªç¯å¤„ç†æ¯åªè‚¡ç¥¨
    total = len(stocks)
    for index, stock in enumerate(stocks):
        print(f"æ­£åœ¨å¤„ç†è‚¡ç¥¨: {stock} ({index+1}/{total})")
        file_path = None  # åˆå§‹åŒ–æ–‡ä»¶è·¯å¾„
        try:
            # è·å–æ•°æ®å¹¶ä¿å­˜åˆ°CSVæ–‡ä»¶
            result = get_and_save_stock_data(stock=stock, start_date=intraday_start_date, end_date=intraday_end_date, kline_days=kline_days)
            if result[0] is None:
                print(f"è‚¡ç¥¨ {stock} è·å–æ•°æ®å¤±è´¥ï¼Œè·³è¿‡")
                continue
            file_paths, stock_name = result

            # ä½¿ç”¨åˆå¹¶çš„å®Œæ•´æ–‡ä»¶è¿›è¡Œä¸Šä¼ 
            main_file_path = file_paths['complete']
            file_id = upload_file(file_path=main_file_path, api_key=api_key)
            if file_id is None:
                print(f"è‚¡ç¥¨ {stock} çš„æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè·³è¿‡")
                continue

            # ä¸é€šä¹‰åƒé—®æ¨¡å‹äº¤äº’ï¼Œç›´æ¥ä¼ é€’å­—å…¸ç±»å‹çš„ prompt_template å’Œé…ç½®å‚æ•°
            response = chat_with_qwen(
                file_id=file_id,
                question=prompt_template,
                api_key=api_key,
                days_before_today=config['daysBeforeToday'],
                kline_days=config['kline_days']
            )
            if response:
                print(f"è‚¡ç¥¨ {stock} çš„åˆ†æç»“æœ: {response}\n")
            else:
                print(f"è‚¡ç¥¨ {stock} çš„èŠå¤©è¯·æ±‚å¤±è´¥ï¼\n")

            # å‘é€é‚®ä»¶å¹¶æ ¹æ®ç»“æœå†³å®šæ˜¯å¦åˆ é™¤æ–‡ä»¶
            print(f"è‚¡ç¥¨ {stock} å‡†å¤‡å‘é€é‚®ä»¶ \n")
            send_email(
                subject=f"è‚¡ç¥¨ {stock} åˆ†æç»“æœ",
                body=response,
                receivers=email_receivers,
                sender=email_sender,
                password=email_password,
                file_path=main_file_path  # ä¼ é€’åˆå¹¶æ–‡ä»¶è·¯å¾„ä»¥ä¾¿åˆ é™¤
            )

        except Exception as e:
            print(f"å¤„ç†è‚¡ç¥¨ {stock} æ—¶å‡ºé”™: {e}\n")

        if index < total - 1:
            for i in range(60):  # ç­‰å¾… 300 ç§’ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                print(".", end="", flush=True)
                t.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

# è¿è¡Œç¨‹åº
if __name__ == "__main__":
    analyze_stocks('anylizeconfig.json', 'keys.json')
