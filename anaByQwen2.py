import akshare as ak
import random
import json
import pandas as pd
from datetime import datetime, timedelta, date
from typing import List, Dict, Any
from openai import OpenAI
import os
from pathlib import Path
import smtplib
import sys
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
import time as t
from md_to_html import MarkdownToHTMLConverter

def send_email(subject: str, body: str, receivers: List[str], sender: str, password: str, attachment_path: str = None) -> bool:
    """å‘é€é‚®ä»¶å¹¶è¿”å›æ˜¯å¦æˆåŠŸï¼Œå¦‚æœæä¾›attachment_pathåˆ™å‘é€HTMLé™„ä»¶"""
    # åˆ›å»ºé‚®ä»¶å¯¹è±¡
    msg = MIMEMultipart()
    msg['From'] = sender  # å‘ä»¶äºº
    msg['To'] = ', '.join(receivers)  # å°†æ”¶ä»¶äººåˆ—è¡¨è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
    msg['Subject'] = subject

    # æ·»åŠ é‚®ä»¶æ­£æ–‡
    msg.attach(MIMEText(body, 'plain', 'utf-8'))

    # å¦‚æœæä¾›äº†é™„ä»¶è·¯å¾„ï¼Œæ·»åŠ HTMLé™„ä»¶
    if attachment_path and os.path.exists(attachment_path):
        try:
            with open(attachment_path, 'rb') as f:
                attachment = MIMEApplication(f.read(), _subtype='html')
                attachment.add_header('Content-Disposition', 'attachment', filename=os.path.basename(attachment_path))
                msg.attach(attachment)
            print(f"å·²æ·»åŠ é™„ä»¶: {attachment_path}")
        except Exception as e:
            print(f"æ·»åŠ é™„ä»¶å¤±è´¥: {e}")
            return False

    # SMTPæœåŠ¡å™¨è®¾ç½®
    smtp_server = 'applesmtp.163.com'
    smtp_port = 465

    # ç™»å½•å‡­è¯ï¼ˆä½¿ç”¨æˆæƒç ï¼‰
    username = sender

    # å‘é€é‚®ä»¶
    try:
        server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        server.login(username, password)
        server.sendmail(sender, receivers, msg.as_string())
        server.quit()
        print("é‚®ä»¶å‘é€æˆåŠŸï¼")
        # å¦‚æœé‚®ä»¶å‘é€æˆåŠŸä¸”æä¾›äº†é™„ä»¶è·¯å¾„ï¼Œåˆ™åˆ é™¤æœ¬åœ°æ–‡ä»¶
        if attachment_path and os.path.exists(attachment_path):
            #os.remove(attachment_path)
            print(f"æœ¬åœ°æ–‡ä»¶ {attachment_path} å·²åˆ é™¤")
        return True
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼š{e}")
        return False

def load_config(config_file: str, keys_file: str) -> Dict[str, Any]:
    """è¯»å– JSON é…ç½®æ–‡ä»¶å¹¶è¿”å›é…ç½®å­—å…¸"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        with open(keys_file, 'r', encoding='utf-8') as f:
            keys = json.load(f)
        config.update(keys)  # åˆå¹¶ keys.json ä¸­çš„é…ç½®
        return config
    except Exception as e:
        raise Exception(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

def select_stocks(config: Dict[str, Any]) -> List[str]:
    """æ ¹æ®é…ç½®æ–‡ä»¶é€‰æ‹©è‚¡ç¥¨"""
    if config['stock_selection'] == 'specified':
        return config['specified_stocks']
    elif config['stock_selection'] == 'random':
        all_stocks = ak.stock_zh_a_spot_em()['ä»£ç '].tolist()
        return random.sample(all_stocks, min(config['random_stock_count'], len(all_stocks)))
    else:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­çš„ 'stock_selection' å¿…é¡»æ˜¯ 'specified' æˆ– 'random'")

def get_trading_dates(start_date: str, end_date: str) -> List[str]:
    """
    è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„äº¤æ˜“æ—¥åˆ—è¡¨ã€‚
    
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: list, äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œæ ¼å¼ä¸º 'YYYYMMDD'
    """
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    start_date_dt = pd.to_datetime(start_date)
    end_date_dt = pd.to_datetime(end_date)
    trading_dates = calendar[(calendar['trade_date'] >= start_date_dt) & 
                             (calendar['trade_date'] <= end_date_dt)]['trade_date']
    return trading_dates.dt.strftime('%Y%m%d').tolist()

def get_intraday_data(stock: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„åˆ†æ—¶æˆäº¤æ•°æ®ã€‚
    
    :param stock: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: pd.DataFrame, åˆ†æ—¶æˆäº¤æ•°æ®ï¼Œsymbol å’Œ name åˆ—å·²åˆ é™¤
    """
    # æ ¹æ®è‚¡ç¥¨ä»£ç å‰ç¼€è°ƒæ•´åˆ†é’Ÿçº¿ä»£ç 
    if stock.startswith('688'):
        minute_code = f"sh{stock}"
    elif stock.startswith(('83', '43', '87')):
        minute_code = f"bj{stock}"
    elif stock.startswith('60'):
        minute_code = f"sh{stock}"
    elif stock.startswith(('00', '30')):
        minute_code = f"sz{stock}"
    else:
        minute_code = stock
    print(f"minute_code: {minute_code}")

    trading_dates = get_trading_dates(start_date, end_date)
    stock_data_list = []
    for date in trading_dates:
        max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        for attempt in range(max_retries):
            try:
                daily_data = ak.stock_intraday_sina(symbol=minute_code, date=date)
                if not daily_data.empty:
                    daily_data['ticktime'] = pd.to_datetime(date + ' ' + daily_data['ticktime'])
                    stock_data_list.append(daily_data)
                    print(f"æˆåŠŸè·å– {minute_code} åœ¨ {date} çš„æ•°æ®")
                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œç­‰å¾… 2 åˆ†é’Ÿ
                    if date != trading_dates[-1]:
                        print("ç¨ç­‰ä¸€ä¸‹...")
                        for _ in range(random.randint(1, 10)):  # ç­‰å¾…éšæœºç§’æ•°ï¼Œæ¯ç§’æ‰“å°ä¸€ä¸ªâ€œ.â€
                            print(".", end="", flush=True)
                            t.sleep(1)
                        print()  # æ¢è¡Œ
                    break  # æˆåŠŸè·å–æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
            except Exception as e:
                print(f"è·å–è‚¡ç¥¨ {minute_code} åœ¨ {date} çš„æ•°æ®æ—¶å‡ºé”™: {e}")
                if attempt < max_retries - 1:  # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…é‡è¯•
                    print("ç­‰å¾…20ç§’åé‡è¯•...")
                    for _ in range(10):  # ç­‰å¾…600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰ï¼Œæ¯2ç§’æ‰“å°ä¸€ä¸ªâ€œ.â€
                        print(".", end="", flush=True)
                        t.sleep(2)
                    print()  # æ¢è¡Œ
                else:
                    print(f"è‚¡ç¥¨ {minute_code} åœ¨ {date} çš„æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡")
                    break  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³å‡ºå¾ªç¯

    if not stock_data_list:
        raise ValueError(f"æ— æ³•è·å– {minute_code} çš„é€ç¬”æˆäº¤æ•°æ®")
    stock_name = daily_data['name'][0]
    all_data = pd.concat(stock_data_list)
    all_data = all_data.sort_values('ticktime').reset_index(drop=True)
    all_data = all_data.drop(columns=['symbol', 'name'], errors='ignore')
    return all_data, stock_name

def get_daily_kline_data(symbol: str, end_date: str, kline_days: int) -> pd.DataFrame:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨æœ€è¿‘ kline_days ä¸ªäº¤æ˜“æ—¥çš„æ—¥Kçº¿æ•°æ®ã€‚
    
    :param symbol: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '300680'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, éœ€è¦çš„äº¤æ˜“æ—¥æ•°é‡ï¼Œä¾‹å¦‚ 60
    :return: pd.DataFrame, æ—¥Kçº¿æ•°æ®
    """
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    end_dt = pd.to_datetime(end_date)
    
    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ <= end_dtï¼Œé™åºæ’åºï¼Œå–å‰ kline_days ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
    trading_dates_filtered = calendar[calendar['trade_date'] <= end_dt]['trade_date'].sort_values(ascending=False).head(kline_days)
    
    if len(trading_dates_filtered) < kline_days:
        print(f"Warning: Only {len(trading_dates_filtered)} trading days available up to {end_date}")
    
    start_dt_kline = trading_dates_filtered.iloc[-1]  # æœ€æ—©çš„æ—¥æœŸåœ¨æœ€åé¢ï¼Œå› ä¸ºæ˜¯é™åº
    end_dt_kline = trading_dates_filtered.iloc[0]  # æœ€æ™šçš„æ—¥æœŸåœ¨æœ€å‰é¢
    
    start_date_kline = start_dt_kline.strftime('%Y%m%d')
    end_date_kline = end_dt_kline.strftime('%Y%m%d')
    
    # è·å–æ—¥Kçº¿æ•°æ®
    stock_data = ak.stock_zh_a_hist(symbol=symbol, period="daily", start_date=start_date_kline, end_date=end_date_kline, adjust="")
    return stock_data

def get_market_index_data(stock_code: str, start_date: str, end_date: str, kline_days: int = 30) -> dict:
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç è·å–å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°æ—¥Kçº¿æ•°æ®ï¼Œæ”¯æŒå¤šä¸ªæŒ‡æ•°ï¼ˆä¸»æ¿æŒ‡æ•°+æ¿å—æŒ‡æ•°ï¼‰ã€‚

    :param stock_code: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, è·å–çš„Kçº¿å¤©æ•°ï¼Œé»˜è®¤30å¤©
    :return: dict, {æŒ‡æ•°åç§°: (pd.DataFrame, æŒ‡æ•°å…¨ç§°)} - å¤šä¸ªæŒ‡æ•°çš„æ•°æ®å­—å…¸
    """
    print(f"æ­£åœ¨è·å–è‚¡ç¥¨ {stock_code} å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°æ•°æ®...")

    # æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šéœ€è¦è·å–çš„æŒ‡æ•°åˆ—è¡¨
    index_configs = {}

    if stock_code.startswith('60'):
        # ä¸Šæµ·ä¸»æ¿ï¼šä¸Šè¯æŒ‡æ•°
        index_configs = {
            "ä¸Šè¯æŒ‡æ•°": ("000001", "ä¸Šè¯æŒ‡æ•°")
        }
        print("è¯†åˆ«ä¸ºä¸Šæµ·ä¸»æ¿è‚¡ç¥¨ï¼Œä½¿ç”¨ä¸Šè¯æŒ‡æ•°")
    elif stock_code.startswith('688'):
        # ç§‘åˆ›æ¿ï¼šä¸Šè¯æŒ‡æ•° + ç§‘åˆ›50
        index_configs = {
            "ä¸Šè¯æŒ‡æ•°": ("000001", "ä¸Šè¯æŒ‡æ•°"),
            "ç§‘åˆ›50": ("000688", "ç§‘åˆ›50æŒ‡æ•°")
        }
        print("è¯†åˆ«ä¸ºç§‘åˆ›æ¿è‚¡ç¥¨ï¼Œä½¿ç”¨ä¸Šè¯æŒ‡æ•°å’Œç§‘åˆ›50æŒ‡æ•°")
    elif stock_code.startswith('00'):
        # æ·±åœ³ä¸»æ¿ï¼šæ·±åœ³æˆæŒ‡
        index_configs = {
            "æ·±åœ³æˆæŒ‡": ("399001", "æ·±åœ³æˆæŒ‡")
        }
        print("è¯†åˆ«ä¸ºæ·±åœ³ä¸»æ¿è‚¡ç¥¨ï¼Œä½¿ç”¨æ·±åœ³æˆæŒ‡")
    elif stock_code.startswith('30'):
        # åˆ›ä¸šæ¿ï¼šæ·±åœ³æˆæŒ‡ + åˆ›ä¸šæ¿æŒ‡æ•°
        index_configs = {
            "æ·±åœ³æˆæŒ‡": ("399001", "æ·±åœ³æˆæŒ‡"),
            "åˆ›ä¸šæ¿æŒ‡æ•°": ("399006", "åˆ›ä¸šæ¿æŒ‡æ•°")
        }
        print("è¯†åˆ«ä¸ºåˆ›ä¸šæ¿è‚¡ç¥¨ï¼Œä½¿ç”¨æ·±åœ³æˆæŒ‡å’Œåˆ›ä¸šæ¿æŒ‡æ•°")
    elif stock_code.startswith(('83', '43', '87')):
        # åŒ—äº¤æ‰€ï¼šåŒ—è¯50
        index_configs = {
            "åŒ—è¯50": ("899050", "åŒ—è¯50æŒ‡æ•°")
        }
        print("è¯†åˆ«ä¸ºåŒ—äº¤æ‰€è‚¡ç¥¨ï¼Œä½¿ç”¨åŒ—è¯50æŒ‡æ•°")
    else:
        # é»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
        index_configs = {
            "ä¸Šè¯æŒ‡æ•°": ("000001", "ä¸Šè¯æŒ‡æ•°")
        }
        print("æ— æ³•è¯†åˆ«å¸‚åœºç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•°")

    result_data = {}

    for short_name, (index_code, full_name) in index_configs.items():
        try:
            # ç‰¹æ®Šå¤„ç†ä¸Šè¯æŒ‡æ•°ï¼Œé¿å…ä¸å¹³å®‰é“¶è¡Œä»£ç å†²çª
            if index_code == "000001":
                # ä½¿ç”¨æŒ‡æ•°ä¸“ç”¨APIè·å–ä¸Šè¯æŒ‡æ•°æ•°æ®
                index_data = ak.stock_zh_index_daily(symbol="sh000001")
                # è·å–æœ€è¿‘ kline_days å¤©çš„ä¸Šè¯æŒ‡æ•°æ•°æ®
                index_data = index_data.tail(kline_days)
                # å°†è‹±æ–‡åˆ—åè½¬æ¢ä¸ºä¸­æ–‡åˆ—åï¼Œä¸å…¶ä»–æŒ‡æ•°ä¿æŒä¸€è‡´
                index_data = index_data.rename(columns={
                    'date': 'æ—¥æœŸ',
                    'open': 'å¼€ç›˜',
                    'high': 'æœ€é«˜',
                    'low': 'æœ€ä½',
                    'close': 'æ”¶ç›˜',
                    'volume': 'æˆäº¤é‡'
                })
                print(f"âœ… ä½¿ç”¨æŒ‡æ•°ä¸“ç”¨APIè·å– {full_name} æ•°æ®æˆåŠŸ")
            else:
                # å…¶ä»–æŒ‡æ•°ä½¿ç”¨åŸæœ‰çš„æ–¹æ³•
                index_data = ak.stock_zh_a_hist(symbol=index_code, period="daily",
                                              start_date=start_date, end_date=end_date, adjust="")

            if index_data.empty:
                print(f"âŒ è·å– {full_name} æ•°æ®å¤±è´¥ï¼Œè·³è¿‡")
                continue

            print(f"âœ… {full_name} æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(index_data)} æ¡è®°å½•")
            if not index_data.empty:
                print(f"   æ—¶é—´èŒƒå›´: {index_data['æ—¥æœŸ'].min()} åˆ° {index_data['æ—¥æœŸ'].max()}")

            result_data[short_name] = (index_data, full_name)

        except Exception as e:
            print(f"âŒ è·å– {full_name} æ•°æ®æ—¶å‡ºé”™: {e}")
            continue

    if not result_data:
        print("âŒ æœªèƒ½è·å–ä»»ä½•æŒ‡æ•°æ•°æ®")
        return {"æœªçŸ¥æŒ‡æ•°": (pd.DataFrame(), "æœªçŸ¥æŒ‡æ•°")}

    return result_data

def get_industry_sector_data(stock_code: str, start_date: str, end_date: str) -> tuple:
    """
    è·å–è‚¡ç¥¨æ‰€å±è¡Œä¸šæ¿å—çš„æ—¥Kçº¿æ•°æ®å’Œæ¿å—åç§°ã€‚

    :param stock_code: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '600000'
    :param start_date: str, èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :return: tuple, (pd.DataFrame, str) - è¡Œä¸šæ¿å—æ—¥Kçº¿æ•°æ®å’Œæ¿å—åç§°
    """
    print(f"æ­£åœ¨è·å–è‚¡ç¥¨ {stock_code} æ‰€å±è¡Œä¸šæ¿å—æ•°æ®...")

    try:
        # æ­¥éª¤1: è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_info_df = ak.stock_individual_info_em(symbol=stock_code)

        if stock_info_df.empty:
            print("âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥")
            return pd.DataFrame(), "æœªçŸ¥æ¿å—"

        # ä»DataFrameä¸­æå–ä¿¡æ¯
        info_dict = dict(zip(stock_info_df['item'], stock_info_df['value']))

        stock_name = info_dict.get('è‚¡ç¥¨ç®€ç§°', 'æœªçŸ¥')
        industry_name = info_dict.get('è¡Œä¸š', 'æœªçŸ¥')

        print(f"âœ… è‚¡ç¥¨ä¿¡æ¯è·å–æˆåŠŸ: {stock_name}")
        print(f"   è¡Œä¸šåˆ†ç±»: {industry_name}")

        if industry_name == 'æœªçŸ¥' or not industry_name:
            print("âŒ æ— æ³•è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯")
            return pd.DataFrame(), "æœªçŸ¥æ¿å—"

        # æ­¥éª¤2: è·å–è¡Œä¸šæ¿å—æ•°æ®
        print(f"æ­£åœ¨è·å– '{industry_name}' è¡Œä¸šæ¿å—æ•°æ®...")
        industry_data = ak.stock_board_industry_hist_em(symbol=industry_name,
                                                       start_date=start_date,
                                                       end_date=end_date)

        if industry_data.empty:
            print(f"âŒ è·å– '{industry_name}' è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥")
            print("   å¯èƒ½åŸå› : è¡Œä¸šåç§°æ ¼å¼ä¸åŒ¹é…æˆ–æ•°æ®ä¸å¯ç”¨")
            return pd.DataFrame(), f"{industry_name}(æ•°æ®è·å–å¤±è´¥)"

        print(f"âœ… è¡Œä¸šæ¿å—æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(industry_data)} æ¡è®°å½•")
        print(f"   æ—¶é—´èŒƒå›´: {industry_data['æ—¥æœŸ'].min()} åˆ° {industry_data['æ—¥æœŸ'].max()}")

        return industry_data, industry_name

    except Exception as e:
        print(f"âŒ è·å–è¡Œä¸šæ¿å—æ•°æ®æ—¶å‡ºé”™: {e}")
        return pd.DataFrame(), "æœªçŸ¥æ¿å—"

def get_and_save_stock_data(stock: str, start_date: str, end_date: str, kline_days: int) -> tuple:
    """
    è·å–è‚¡ç¥¨çš„åˆ†æ—¶æˆäº¤æ•°æ®ã€æ—¥Kçº¿æ•°æ®ã€å¤§ç›˜æŒ‡æ•°æ•°æ®å’Œè¡Œä¸šæ¿å—æ•°æ®ï¼Œå¹¶ä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­ã€‚

    :param stock: str, è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ '300680'
    :param start_date: str, åˆ†æ—¶æ•°æ®çš„èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param end_date: str, åˆ†æ—¶æ•°æ®çš„ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    :param kline_days: int, æ—¥Kçº¿æ•°æ®çš„å¤©æ•°ï¼Œä¾‹å¦‚ 60
    :return: tuple, (file_paths, stock_name) æ–‡ä»¶è·¯å¾„å­—å…¸å’Œè‚¡ç¥¨åç§°ï¼Œå¤±è´¥è¿”å› (None, None)
    """
    try:
        # åˆ†æ—¶æ•°æ®ä½¿ç”¨ä¼ é€’çš„æ—¥æœŸèŒƒå›´ï¼ˆæ¥è‡ªdaysBeforeTodayï¼‰
        df_intraday, stock_name = get_intraday_data(stock=stock, start_date=start_date, end_date=end_date)

        # Kçº¿æ•°æ®ä½¿ç”¨åŸºäºkline_daysè®¡ç®—çš„æ—¥æœŸèŒƒå›´
        kline_start_date, kline_end_date = get_kline_date_range(kline_days)
        df_daily = get_daily_kline_data(symbol=stock, end_date=kline_end_date, kline_days=kline_days)

        # å¤§ç›˜æŒ‡æ•°æ•°æ®ä½¿ç”¨Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´
        market_index_data = get_market_index_data(stock_code=stock, start_date=kline_start_date, end_date=kline_end_date, kline_days=kline_days)

        # è¡Œä¸šæ¿å—æ•°æ®ä½¿ç”¨Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´
        df_industry, industry_sector_name = get_industry_sector_data(stock_code=stock, start_date=kline_start_date, end_date=kline_end_date)

        # ç”Ÿæˆä¸‰ä½éšæœºæ•°ï¼Œé¿å…æ–‡ä»¶åå†²çª
        random_suffix = str(random.randint(0, 999)).zfill(3)
        base_filename = f"{stock}_{stock_name}_{start_date}_to_{end_date}_{random_suffix}"

        # ç¡®ä¿data_outputç›®å½•å­˜åœ¨
        output_dir = Path('data_output')
        output_dir.mkdir(exist_ok=True)

        # ä¿å­˜åˆ°CSVæ–‡ä»¶ - ä»…åˆ›å»ºåˆå¹¶çš„å®Œæ•´æ–‡ä»¶
        file_paths = {}

        # åˆ›å»ºä¸€ä¸ªåˆå¹¶çš„CSVæ–‡ä»¶ç”¨äºä¸Šä¼ åˆ°é€šä¹‰åƒé—®ï¼ˆåŒ…å«æ‰€æœ‰æ•°æ®ï¼‰
        main_file = str(output_dir / f"{base_filename}_complete.csv")
        with open(main_file, 'w', encoding='utf-8-sig', newline='') as f:
            # å†™å…¥æ ‡é¢˜ä¿¡æ¯
            f.write(f"è‚¡ç¥¨ä»£ç : {stock}\n")
            f.write(f"è‚¡ç¥¨åç§°: {stock_name}\n")
            f.write(f"æ‰€å±æ¿å—: {industry_sector_name}\n")
            f.write(f"åˆ†æ—¶æ•°æ®æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}\n")
            f.write(f"Kçº¿æ•°æ®æ—¶é—´èŒƒå›´: {kline_start_date} åˆ° {kline_end_date}\n\n")

            # å†™å…¥åˆ†æ—¶æ•°æ®
            f.write("=== åˆ†æ—¶æˆäº¤æ•°æ® ===\n")
            df_intraday.to_csv(f, index=False)
            f.write("\n\n")

            # å†™å…¥æ—¥Kçº¿æ•°æ®
            f.write("=== æ—¥Kçº¿æ•°æ® ===\n")
            df_daily.to_csv(f, index=False)
            f.write("\n\n")

            # å†™å…¥å¤§ç›˜æŒ‡æ•°æ•°æ®
            if market_index_data:
                for index_short_name, (df_market, market_index_name) in market_index_data.items():
                    if not df_market.empty:
                        f.write(f"=== {market_index_name}æ•°æ® ===\n")
                        df_market.to_csv(f, index=False)
                        f.write("\n\n")

            # å†™å…¥è¡Œä¸šæ¿å—æ•°æ®
            if not df_industry.empty:
                f.write("=== è¡Œä¸šæ¿å—æ•°æ® ===\n")
                df_industry.to_csv(f, index=False)
                f.write("\n\n")

        file_paths['complete'] = main_file
        print(f"âœ… åˆå¹¶æ•°æ®æ–‡ä»¶å·²ä¿å­˜åˆ° {main_file} (ç”¨äºä¸Šä¼ )")

        return file_paths, stock_name

    except Exception as e:
        print(f"âŒ å¤„ç†è‚¡ç¥¨ {stock} æ—¶å‡ºé”™: {e}")
        return None, None

def upload_file(file_path: str, api_key: str) -> str:
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°é€šä¹‰åƒé—®å¹³å°ã€‚
    
    :param file_path: str, æ–‡ä»¶è·¯å¾„
    :param api_key: str, API å¯†é’¥
    :return: str, æ–‡ä»¶ ID
    """
    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    file_object = client.files.create(file=Path(file_path), purpose="file-extract")
    print(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ–‡ä»¶ ID: {file_object.id}")
    return file_object.id

def save_data_to_file(data_text: str, stock_code: str, file_suffix: str = "") -> str:
    """
    å°†æ ¼å¼åŒ–çš„æ•°æ®ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚

    :param data_text: str, æ ¼å¼åŒ–çš„æ•°æ®æ–‡æœ¬
    :param stock_code: str, è‚¡ç¥¨ä»£ç 
    :param file_suffix: str, æ–‡ä»¶åç¼€ï¼Œç”¨äºåŒºåˆ†ä¸åŒç‰ˆæœ¬
    :return: str, ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    import os
    from datetime import datetime

    # åˆ›å»ºæ•°æ®ç›®å½•
    data_dir = "data_output"
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)

    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{data_dir}/{stock_code}_data_{timestamp}{file_suffix}.txt"
    filepath = filename

    # ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(f"=== å‘é€ç»™å¤§æ¨¡å‹çš„æ•°æ® ===\n")
        f.write(f"è‚¡ç¥¨ä»£ç : {stock_code}\n")
        f.write(f"ä¿å­˜æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"=" * 50 + "\n\n")
        f.write(data_text)

    print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {filepath}")
    return filepath

def chat_with_qwen(file_id: str, question: Any, api_key: str, intraday_days: int = 7, kline_days: int = 30, stock_code: str = "") -> str:
    """
    ä½¿ç”¨é€šä¹‰åƒé—®çš„ API è¿›è¡ŒèŠå¤©ï¼Œæ”¯æŒå­—å…¸æˆ–å­—ç¬¦ä¸²ç±»å‹çš„ questionã€‚

    :param file_id: str, æ–‡ä»¶ ID
    :param question: Any, ç”¨æˆ·æç¤ºæˆ–é—®é¢˜ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
    :param api_key: str, API å¯†é’¥
    :param intraday_days: int, åˆ†æ—¶æ•°æ®çš„å¤©æ•°ï¼Œé»˜è®¤7å¤©
    :param kline_days: int, Kçº¿æ•°æ®çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©
    :return: str, èŠå¤©ç»“æœ
    """
    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    # åˆå§‹åŒ– messages åˆ—è¡¨
    messages = [
        {'role': 'system', 'content': 'You are a helpful assistant.'},
        {'role': 'system', 'content': f'fileid://{file_id}'}
    ]

    # å¤„ç† question å‚æ•°
    if isinstance(question, dict):
        # å¦‚æœ question æ˜¯å­—å…¸ï¼Œå‡è®¾å®ƒåŒ…å« analysis_request
        analysis_request = question.get('analysis_request', {})

        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œå…¶æ¬¡ä»questionä¸­è·å–
        intraday_days = intraday_days
        kline_days = kline_days

        # è·å–å½“å‰ç³»ç»Ÿæ—¶é—´å¹¶æ ¼å¼åŒ–
        current_datetime = datetime.now()
        current_date_str = current_datetime.strftime('%Yå¹´%mæœˆ%dæ—¥')
        current_weekday = current_datetime.strftime('%A')  # è‹±æ–‡æ˜ŸæœŸ
        # è½¬æ¢ä¸ºä¸­æ–‡æ˜ŸæœŸ
        weekday_map = {
            'Monday': 'æ˜ŸæœŸä¸€', 'Tuesday': 'æ˜ŸæœŸäºŒ', 'Wednesday': 'æ˜ŸæœŸä¸‰',
            'Thursday': 'æ˜ŸæœŸå››', 'Friday': 'æ˜ŸæœŸäº”', 'Saturday': 'æ˜ŸæœŸå…­', 'Sunday': 'æ˜ŸæœŸæ—¥'
        }
        current_weekday_cn = weekday_map.get(current_weekday, current_weekday)

        # åœ¨æç¤ºè¯å¼€å¤´æ˜ç¡®å£°æ˜å½“å‰æ—¶é—´
        time_declaration = f"""âš ï¸ é‡è¦æ—¶é—´å£°æ˜ï¼šå½“å‰ç³»ç»Ÿæ—¶é—´ä¸º {current_date_str} {current_weekday_cn}ã€‚è¯·åœ¨æ•´ä¸ªåˆ†ææŠ¥å‘Šä¸­ä½¿ç”¨æ­¤æ—¶é—´ä½œä¸ºåŸºå‡†ï¼Œç¡®ä¿æ‰€æœ‰æ—¥æœŸç›¸å…³çš„å†…å®¹éƒ½åŸºäºæ­¤å½“å‰æ—¶é—´è¿›è¡Œè®¡ç®—å’Œæè¿°ã€‚

"""

        # æ„é€ ç”¨æˆ·æ¶ˆæ¯å†…å®¹ - å¢å¼ºçš„åˆ†ææè¿°
        user_content = time_declaration + (
            f"{analysis_request.get('analysis_purpose', {}).get('description', '')}\n\n"
            f"ğŸ“Š æ•°æ®æ—¶é—´èŒƒå›´è¯´æ˜ï¼š\n"
            f"- åˆ†æ—¶æˆäº¤æ•°æ®ï¼šåŒ…å«æœ€è¿‘ {intraday_days} ä¸ªäº¤æ˜“æ—¥çš„æ—¥å†…åˆ†æ—¶æ•°æ®ï¼Œç”¨äºåˆ†æçŸ­æœŸèµ„é‡‘æµå‘å’Œä¸»åŠ›è¡Œä¸ºæ¨¡å¼\n"
            f"- æ—¥Kçº¿æ•°æ®ï¼šåŒ…å«æœ€è¿‘ {kline_days} ä¸ªäº¤æ˜“æ—¥çš„Kçº¿æ•°æ®ï¼Œç”¨äºè¯†åˆ«ä¸­é•¿æœŸè¶‹åŠ¿å’Œå…³é”®æŠ€æœ¯ä½\n"
            f"- å¸‚åœºæŒ‡æ•°æ•°æ®ï¼šå¯¹åº”è‚¡ç¥¨æ‰€å±å¸‚åœºçš„æŒ‡æ•°ï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªæŒ‡æ•°ï¼Œæ ¹æ®æ¿å—è‡ªåŠ¨åŒ¹é…ï¼‰ï¼Œæ—¶é—´èŒƒå›´ä¸Kçº¿æ•°æ®ä¸€è‡´ï¼Œç”¨äºè¯„ä¼°ç³»ç»Ÿæ€§é£é™©å’Œå¸‚åœºbetaç³»æ•°\n"
            f"- è¡Œä¸šæ¿å—æ•°æ®ï¼šè‚¡ç¥¨æ‰€å±è¡Œä¸šçš„æ¿å—æŒ‡æ•°ï¼Œæ—¶é—´èŒƒå›´ä¸Kçº¿æ•°æ®ä¸€è‡´ï¼Œç”¨äºåˆ†æè¡Œä¸šç›¸å¯¹å¼ºåº¦å’Œè½®åŠ¨æœºä¼š\n\n"
            f"ğŸ“‹ æ•°æ®ç»“æ„è¯´æ˜ï¼š\n"
            f"{analysis_request.get('data_description', {}).get('data_structure', '')}\n\n"
            f"ğŸ” æ•°æ®å·¥ä½œè¡¨è¯¦ç»†è¯´æ˜ï¼š\n"
            f"â€¢ åˆ†æ—¶æˆäº¤æ•°æ®æ®µ: {analysis_request.get('data_description', {}).get('intraday_data_section', {}).get('description', '')}\n"
            f"  æ ‡è¯†ç¬¦: {analysis_request.get('data_description', {}).get('intraday_data_section', {}).get('section_marker', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('intraday_data_section', {}).get('fields', []))}\n\n"
            f"â€¢ æ—¥Kçº¿æ•°æ®æ®µ: {analysis_request.get('data_description', {}).get('daily_data_section', {}).get('description', '')}\n"
            f"  æ ‡è¯†ç¬¦: {analysis_request.get('data_description', {}).get('daily_data_section', {}).get('section_marker', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('daily_data_section', {}).get('fields', []))}\n\n"
            f"â€¢ å¸‚åœºæŒ‡æ•°æ•°æ®æ®µ: {analysis_request.get('data_description', {}).get('market_index_data_sections', {}).get('description', '')}\n"
            f"  æ ‡è¯†ç¬¦: {analysis_request.get('data_description', {}).get('market_index_data_sections', {}).get('section_markers', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('market_index_data_sections', {}).get('fields', []))}\n\n"
            f"â€¢ è¡Œä¸šæ¿å—æ•°æ®æ®µ: {analysis_request.get('data_description', {}).get('industry_sector_data_section', {}).get('description', '')}\n"
            f"  æ ‡è¯†ç¬¦: {analysis_request.get('data_description', {}).get('industry_sector_data_section', {}).get('section_marker', '')}\n"
            f"  å­—æ®µ: {', '.join(analysis_request.get('data_description', {}).get('industry_sector_data_section', {}).get('fields', []))}\n\n"
            f"ğŸ“ˆ å¤šæ—¥æ•°æ®åˆ†æè¦æ±‚ï¼š\n"
            f"è¯·å¯¹æä¾›çš„å¤šæ—¥åˆ†æ—¶æ•°æ®è¿›è¡Œé€æ—¥æ·±åº¦åˆ†æï¼ˆæŒ‰æ—¶é—´é¡ºåºç”±è¿œåŠè¿‘ï¼‰\n"
            f"ğŸ”¬ åˆ†ææ­¥éª¤ï¼ˆåº”ç”¨äºæ¯ä¸€å¤©çš„åˆ†æ—¶æ•°æ®åˆ†æç»“æœè¾“å‡ºï¼‰ï¼š\n"
        )

        # æ·»åŠ åˆ†ææ­¥éª¤ - é’ˆå¯¹å¤šæ—¥æ•°æ®è¿›è¡Œé€æ—¥åˆ†æ
        for step in analysis_request.get('analysis_steps', []):
            user_content += f"æ­¥éª¤ {step.get('step', '')}: {step.get('description', '')}\n"

        # ä½¿ç”¨é…ç½®åŒ–çš„è¾“å‡ºè¦æ±‚æ ¼å¼åŒ–
        output_requirements = analysis_request.get('output_requirements', [])
        user_content += format_output_requirements(output_requirements)

        messages.append({'role': 'user', 'content': user_content})
    elif isinstance(question, str):
        # å¦‚æœ question æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆä¿æŒåå‘å…¼å®¹æ€§ï¼‰
        messages.append({'role': 'user', 'content': question})
    else:
        raise ValueError("question å‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ç±»å‹")

    print(messages)

    # ä¿å­˜å®Œæ•´çš„å¯¹è¯å†…å®¹åˆ°æœ¬åœ°æ–‡ä»¶
    if stock_code:
        # å°†messagesæ ¼å¼åŒ–ä¸ºå¯è¯»çš„æ–‡æœ¬
        full_message_content = ""
        for msg in messages:
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            full_message_content += f"=== {role.upper()} ===\n{content}\n\n"

        # ä¿å­˜åˆ°æ–‡ä»¶
        full_message_file = save_data_to_file(full_message_content, stock_code, "_full_message")
        print(f"ğŸ“„ å®Œæ•´æ¶ˆæ¯å·²ä¿å­˜ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹: {full_message_file}")

    # è°ƒç”¨ API
    completion = client.chat.completions.create(
        model="qwen-long",
        messages=messages,
        stream=True,
        stream_options={"include_usage": True}
    )

    full_content = ""
    for chunk in completion:
        if chunk.choices and chunk.choices[0].delta.content:
            full_content += chunk.choices[0].delta.content
            print(".", end="", flush=True)

    return full_content

def format_output_requirements(output_requirements: List[Dict[str, Any]]) -> str:
    """
    æ ¹æ®output_requirementsé…ç½®æ ¼å¼åŒ–è¾“å‡ºè¦æ±‚ã€‚

    :param output_requirements: è¾“å‡ºè¦æ±‚åˆ—è¡¨
    :return: æ ¼å¼åŒ–çš„è¾“å‡ºè¦æ±‚å­—ç¬¦ä¸²
    """
    formatted_content = "\nğŸ“‹ è¾“å‡ºè¦æ±‚ï¼ˆåŸºäºå¤šæ—¥æ•°æ®åˆ†æï¼‰ï¼š\n"

    for req in output_requirements:
        section_num = req.get('section', '')
        title = req.get('title', '')
        description = req.get('description', '')

        # æ·»åŠ sectionæ ‡é¢˜å’Œæè¿°
        formatted_content += f"{section_num}. {title}: {description}\n"

        # å¤„ç†output_format
        output_format = req.get('output_format', {})
        if output_format:
            formatted_content += "\nè¾“å‡ºæ ¼å¼è¦æ±‚ï¼š\n"

            # é€šç”¨å¤„ç†æ‰€æœ‰output_formatä¸­çš„é”®å€¼å¯¹
            for key, value in output_format.items():
                formatted_content += f"{key}: {value}\n"

    return formatted_content

def select_prompt_by_model(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¹æ®å½“å‰è„šæœ¬ä½¿ç”¨çš„æ¨¡å‹æ™ºèƒ½é€‰æ‹©å¯¹åº”çš„prompté…ç½®ã€‚

    :param config: é…ç½®å­—å…¸
    :return: å¯¹åº”çš„prompté…ç½®
    """
    # å¯¹äºqwen-longï¼Œä½¿ç”¨åŸæœ‰çš„é€šç”¨promptï¼ˆåŒ…å«åˆ†æ—¶æ•°æ®å¤„ç†ï¼‰
    if 'prompt' in config:
        print("ğŸ¯ æ£€æµ‹åˆ°æ–‡ä»¶å¤„ç†æ¨¡å‹ä¸“ç”¨prompté…ç½®")
        return config['prompt']

    # å›é€€åˆ°é€šç”¨prompt
    print("â„¹ï¸ æœªæ‰¾åˆ°ä¸“ç”¨promptï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    return {}

def get_kline_date_range(kline_days: int) -> tuple:
    """
    æ ¹æ®kline_daysè®¡ç®—Kçº¿æ•°æ®çš„æ—¥æœŸèŒƒå›´ã€‚

    :param kline_days: int, Kçº¿æ•°æ®çš„å¤©æ•°
    :return: tuple, (start_date, end_date) æ ¼å¼ä¸ºYYYYMMDD
    """
    end_date = date.today().strftime('%Y%m%d')

    # è®¡ç®—Kçº¿æ•°æ®çš„å¼€å§‹æ—¥æœŸï¼ˆå¾€å‰kline_daysä¸ªäº¤æ˜“æ—¥ï¼‰
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    end_dt = pd.to_datetime(end_date)

    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ <= end_dtï¼Œé™åºæ’åºï¼Œå–å‰ kline_days ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
    trading_dates_filtered = calendar[calendar['trade_date'] <= end_dt]['trade_date'].sort_values(ascending=False).head(kline_days)

    if len(trading_dates_filtered) < kline_days:
        print(f"âš ï¸ è­¦å‘Š: ä»…æ‰¾åˆ° {len(trading_dates_filtered)} ä¸ªäº¤æ˜“æ—¥ï¼Œå¯ç”¨äº¤æ˜“æ—¥ä¸è¶³ {kline_days} å¤©")

    start_dt_kline = trading_dates_filtered.iloc[-1]  # æœ€æ—©çš„æ—¥æœŸåœ¨æœ€åé¢ï¼Œå› ä¸ºæ˜¯é™åº
    start_date = start_dt_kline.strftime('%Y%m%d')

    return start_date, end_date

def get_intraday_date_range(days_before_today: int) -> tuple:
    """
    æ ¹æ®days_before_todayè®¡ç®—åˆ†æ—¶æ•°æ®çš„æ—¥æœŸèŒƒå›´ï¼Œä½¿ç”¨äº¤æ˜“æ—¥è€Œéè‡ªç„¶æ—¥ã€‚

    :param days_before_today: int, åˆ†æ—¶æ•°æ®å¾€å‰è¿½æº¯çš„äº¤æ˜“æ—¥æ•°é‡
    :return: tuple, (start_date, end_date) æ ¼å¼ä¸ºYYYYMMDD
    """
    end_date = date.today().strftime('%Y%m%d')

    # è®¡ç®—åˆ†æ—¶æ•°æ®çš„å¼€å§‹æ—¥æœŸï¼ˆå¾€å‰days_before_todayä¸ªäº¤æ˜“æ—¥ï¼‰
    calendar = ak.tool_trade_date_hist_sina()
    calendar['trade_date'] = pd.to_datetime(calendar['trade_date'])
    end_dt = pd.to_datetime(end_date)

    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ <= end_dtï¼Œé™åºæ’åºï¼Œå–å‰ days_before_today ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
    trading_dates_filtered = calendar[calendar['trade_date'] <= end_dt]['trade_date'].sort_values(ascending=False).head(days_before_today)

    if len(trading_dates_filtered) < days_before_today:
        print(f"âš ï¸ è­¦å‘Š: ä»…æ‰¾åˆ° {len(trading_dates_filtered)} ä¸ªäº¤æ˜“æ—¥ï¼Œå¯ç”¨äº¤æ˜“æ—¥ä¸è¶³ {days_before_today} å¤©")

    start_dt_intraday = trading_dates_filtered.iloc[-1]  # æœ€æ—©çš„æ—¥æœŸåœ¨æœ€åé¢ï¼Œå› ä¸ºæ˜¯é™åº
    start_date = start_dt_intraday.strftime('%Y%m%d')

    return start_date, end_date

def analyze_stocks(config_file: str = 'anylizeconfig.json', keys_file: str = 'keys.json', command_line_stocks: List[str] = None):
    """åˆ†æè‚¡ç¥¨çš„ä¸»å‡½æ•°

    :param config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    :param keys_file: å¯†é’¥æ–‡ä»¶è·¯å¾„
    :param command_line_stocks: å‘½ä»¤è¡Œä¼ å…¥çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚æœæä¾›åˆ™ä¼˜å…ˆä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶
    """
    # 1. è¯»å–é…ç½®
    config = load_config(config_file, keys_file)

    # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œè‚¡ç¥¨å‚æ•°ï¼Œä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼›å¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶
    if command_line_stocks:
        stocks = command_line_stocks
        print(f"ğŸ’´ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„è‚¡ç¥¨: {', '.join(stocks)}")
    else:
        stocks = select_stocks(config)
        print(f"ğŸ’´ ä½¿ç”¨é…ç½®æ–‡ä»¶æŒ‡å®šçš„è‚¡ç¥¨: {', '.join(stocks)}")

    # åˆ†æ—¶æ•°æ®ä½¿ç”¨intraday_daysè®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆåŸºäºäº¤æ˜“æ—¥ï¼‰
    intraday_days = config['intraday_days']
    intraday_start_date, intraday_end_date = get_intraday_date_range(intraday_days)
    print(f"ğŸ“… åˆ†æ—¶æ•°æ®æ—¥æœŸèŒƒå›´: {intraday_start_date} åˆ° {intraday_end_date} (å…±{intraday_days}ä¸ªäº¤æ˜“æ—¥)")

    # Kçº¿æ•°æ®ä½¿ç”¨kline_daysè®¡ç®—æ—¥æœŸèŒƒå›´
    kline_days = config.get('kline_days', 60)  # é»˜è®¤60å¤©
    kline_start_date, kline_end_date = get_kline_date_range(kline_days)
    print(f"ğŸ“… Kçº¿æ•°æ®æ—¥æœŸèŒƒå›´: {kline_start_date} åˆ° {kline_end_date} (å…±{kline_days}ä¸ªäº¤æ˜“æ—¥)")

    # æ™ºèƒ½é€‰æ‹©prompté…ç½®
    prompt_template = select_prompt_by_model(config)
    print(f"ğŸ¯ ä½¿ç”¨æ–‡ä»¶å¤„ç†æ¨¡å‹ä¸“ç”¨prompt (qwen-long)")

    api_key = config['api_key']  # ä» keys.json è¯»å– API å¯†é’¥
    email_sender = config['email_sender']  # ä» keys.json è¯»å–å‘ä»¶äººé‚®ç®±åœ°å€
    email_password = config['email_password']  # ä» keys.json è¯»å–å‘ä»¶äººé‚®ç®±å¯†ç 
    email_receivers = config['email_receivers']  # ä» keys.json è¯»å–æ”¶ä»¶äººé‚®ç®±åœ°å€

    # 2. å¾ªç¯å¤„ç†æ¯åªè‚¡ç¥¨
    total = len(stocks)
    for index, stock in enumerate(stocks):
        print(f"æ­£åœ¨å¤„ç†è‚¡ç¥¨: {stock} ({index+1}/{total})")
        file_path = None  # åˆå§‹åŒ–æ–‡ä»¶è·¯å¾„
        try:
            # è·å–æ•°æ®å¹¶ä¿å­˜åˆ°CSVæ–‡ä»¶
            result = get_and_save_stock_data(stock=stock, start_date=intraday_start_date, end_date=intraday_end_date, kline_days=kline_days)
            if result[0] is None:
                print(f"è‚¡ç¥¨ {stock} è·å–æ•°æ®å¤±è´¥ï¼Œè·³è¿‡")
                continue
            file_paths, stock_name = result

            # ä½¿ç”¨åˆå¹¶çš„å®Œæ•´æ–‡ä»¶è¿›è¡Œä¸Šä¼ 
            main_file_path = file_paths['complete']
            file_id = upload_file(file_path=main_file_path, api_key=api_key)
            if file_id is None:
                print(f"è‚¡ç¥¨ {stock} çš„æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè·³è¿‡")
                continue

            # ä¸é€šä¹‰åƒé—®æ¨¡å‹äº¤äº’ï¼Œç›´æ¥ä¼ é€’å­—å…¸ç±»å‹çš„ prompt_template å’Œé…ç½®å‚æ•°
            response = chat_with_qwen(
                file_id=file_id,
                question=prompt_template,
                api_key=api_key,
                intraday_days=config['intraday_days'],
                kline_days=config['kline_days'],
                stock_code=stock
            )
            if response:
                print(f"è‚¡ç¥¨ {stock} çš„åˆ†æç»“æœ: {response}\n")

                # ä¿å­˜åˆ†æç»“æœåˆ°MDæ–‡ä»¶
                current_time = datetime.now()
                date_str = current_time.strftime('%Y%m%d')
                time_str = current_time.strftime('%H%M%S')

                # ç¡®ä¿data_outputæ–‡ä»¶å¤¹å­˜åœ¨
                output_dir = Path('data_output')
                output_dir.mkdir(exist_ok=True)

                # æ¸…ç†è‚¡ç¥¨åç§°ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                clean_stock_name = stock_name.replace('(', '').replace(')', '').replace(' ', '_')

                md_filename = f"{stock}_{clean_stock_name}_{intraday_start_date}_to_{intraday_end_date}_{date_str}_{time_str}.md"
                md_filepath = output_dir / md_filename

                with open(md_filepath, 'w', encoding='utf-8') as f:
                    f.write(f"# {stock_name}ï¼ˆ{stock}ï¼‰è‚¡ç¥¨åˆ†ææŠ¥å‘Š\n\n")
                    f.write(f"**åˆ†ææ—¶é—´**: {current_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
                    f.write(f"---\n\n")
                    f.write(response)

                print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {md_filepath}")

                # å°†MDæ–‡ä»¶è½¬æ¢ä¸ºHTML
                html_filename = md_filename.replace('.md', '.html')
                html_filepath = output_dir / html_filename
                converter = MarkdownToHTMLConverter()
                if converter.convert_file(str(md_filepath), str(html_filepath)):
                    print(f"âœ… HTMLæ–‡ä»¶å·²ç”Ÿæˆ: {html_filepath}\n")
                else:
                    print(f"âŒ HTMLè½¬æ¢å¤±è´¥: {md_filepath}\n")
                    continue
            else:
                print(f"è‚¡ç¥¨ {stock} çš„èŠå¤©è¯·æ±‚å¤±è´¥ï¼\n")

            # å‘é€é‚®ä»¶å¹¶æ ¹æ®ç»“æœå†³å®šæ˜¯å¦åˆ é™¤æ–‡ä»¶
            print(f"è‚¡ç¥¨ {stock} å‡†å¤‡å‘é€é‚®ä»¶ \n")
            send_email(
                subject=f"è‚¡ç¥¨ {stock} åˆ†æç»“æœ",
                body=f"è‚¡ç¥¨ {stock_name}ï¼ˆ{stock}ï¼‰çš„åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹é™„ä»¶ä¸­çš„HTMLæ–‡ä»¶ã€‚",
                receivers=email_receivers,
                sender=email_sender,
                password=email_password,
                attachment_path=str(html_filepath)  # å‘é€HTMLæ–‡ä»¶ä½œä¸ºé™„ä»¶
            )

        except Exception as e:
            print(f"å¤„ç†è‚¡ç¥¨ {stock} æ—¶å‡ºé”™: {e}\n")

        if index < total - 1:
            for i in range(60):  # ç­‰å¾… 300 ç§’ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                print(".", end="", flush=True)
                t.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

# è¿è¡Œç¨‹åº
if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°ï¼Œå¦‚æœæœ‰å‚æ•°ï¼ˆé™¤äº†è„šæœ¬åï¼‰ï¼Œåˆ™å°†å…¶ä½œä¸ºè‚¡ç¥¨ä»£ç ä½¿ç”¨
    if len(sys.argv) > 1:
        # sys.argv[0] æ˜¯è„šæœ¬åï¼Œåé¢çš„å‚æ•°éƒ½æ˜¯è‚¡ç¥¨ä»£ç 
        command_line_stocks = sys.argv[1:]
        print(f"ğŸ”§ æ£€æµ‹åˆ°å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨ä»£ç : {', '.join(command_line_stocks)}")
        analyze_stocks('anylizeconfig.json', 'keys.json', command_line_stocks)
    else:
        print("ğŸ”§ æœªæ£€æµ‹åˆ°å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è‚¡ç¥¨è®¾ç½®")
        analyze_stocks('anylizeconfig.json', 'keys.json')
