#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨è‚¡ç¥¨åˆ†æè„šæœ¬

åŠŸèƒ½ï¼š
- åœ¨éäº¤æ˜“æ—¶é—´ï¼ˆ17:00-æ¬¡æ—¥6:00ï¼‰è‡ªåŠ¨éšæœºåˆ†æè‚¡ç¥¨
- é¿å…é‡å¤åˆ†æåŒä¸€åªè‚¡ç¥¨
- æ™ºèƒ½æ§åˆ¶APIè°ƒç”¨é—´éš”ï¼Œé˜²æ­¢è¢«å°IP
- æŒç»­è¿è¡Œï¼Œé™¤éäººå·¥å¹²é¢„é€€å‡º

ä½¿ç”¨æ–¹æ³•ï¼š
python auto_analyze_stocks.py

é…ç½®æ–‡ä»¶ï¼š
- analyzeconfig.json: ä¸»è¦é…ç½®æ–‡ä»¶ï¼ˆå¿…é¡»ï¼‰
- keys.json: å¯†é’¥æ–‡ä»¶ï¼ˆå¿…é¡»ï¼‰

é…ç½®æ–‡ä»¶æ¨¡æ¿å·²æä¾›ï¼šanalyzeconfig_template.json

ä¾èµ–ï¼š
- anaByQwen2.py: å¤ç”¨è‚¡ç¥¨åˆ†æç›¸å…³å‡½æ•°
- md_to_html.py: Markdownè½¬HTMLå·¥å…·
"""

import akshare as ak
import random
import json
import pandas as pd
from datetime import datetime, timedelta, date
from typing import List, Dict, Any, Optional
from pathlib import Path
import time as t
import sys
import signal
import traceback
import logging
from logging.handlers import RotatingFileHandler
import os

# ä»anaByQwen2.pyå¯¼å…¥éœ€è¦çš„å‡½æ•°
import anaByQwen2  # å¯¼å…¥æ•´ä¸ªæ¨¡å—ä»¥ä¾¿ä¿®æ”¹å¸¸é‡
from anaByQwen2 import (
    load_config,
    get_and_save_stock_data,
    upload_file,
    chat_with_qwen,
    send_email,
    cleanup_stock_data,
    extract_investment_rating,
    select_prompt_by_model,
    get_kline_date_range,
    get_intraday_date_range,
    get_stock_output_dir
)
from md_to_html import MarkdownToHTMLConverter

# ===== é…ç½®å¸¸é‡ =====
DEFAULT_STOCKS_LIST_FILE = 'all_stocks_list.csv'
DEFAULT_ANALYZED_RECORDS_FILE = 'analyzed_stocks.json'
DEFAULT_LOG_FILE = 'auto_analyze_log.txt'
DEFAULT_CONFIG_FILE = 'analyzeconfig.json'
DEFAULT_KEYS_FILE = 'keys.json'

# ===== APIè°ƒç”¨é—´éš”æ§åˆ¶å™¨ =====
class APICallIntervalController:
    """
    APIè°ƒç”¨é—´éš”æ§åˆ¶å™¨
    
    åŠŸèƒ½ï¼š
    - æ­£å¸¸é—´éš”ï¼š1-2åˆ†é’Ÿéšæœº
    - è¿ç»­å¤±è´¥3æ¬¡åï¼šç­‰å¾…15åˆ†é’Ÿï¼Œé—´éš”å»¶é•¿è‡³2-4åˆ†é’Ÿ
    - æˆåŠŸä¸€æ¬¡åé‡ç½®å¤±è´¥è®¡æ•°å’Œé—´éš”
    """
    
    def __init__(self, 
                 normal_min: int = 60, 
                 normal_max: int = 120,
                 extended_min: int = 120,
                 extended_max: int = 240,
                 failure_wait_time: int = 900,
                 failure_threshold: int = 3):
        """
        åˆå§‹åŒ–é—´éš”æ§åˆ¶å™¨
        
        :param normal_min: æ­£å¸¸é—´éš”æœ€å°å€¼ï¼ˆç§’ï¼‰
        :param normal_max: æ­£å¸¸é—´éš”æœ€å¤§å€¼ï¼ˆç§’ï¼‰
        :param extended_min: å»¶é•¿é—´éš”æœ€å°å€¼ï¼ˆç§’ï¼‰
        :param extended_max: å»¶é•¿é—´éš”æœ€å¤§å€¼ï¼ˆç§’ï¼‰
        :param failure_wait_time: è¿ç»­å¤±è´¥åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        :param failure_threshold: è¿ç»­å¤±è´¥é˜ˆå€¼
        """
        self.normal_min = normal_min
        self.normal_max = normal_max
        self.extended_min = extended_min
        self.extended_max = extended_max
        self.failure_wait_time = failure_wait_time
        self.failure_threshold = failure_threshold
        
        self.consecutive_failures = 0
        self.is_extended_interval = False
        self.last_failure_time = None
    
    def get_next_interval(self) -> int:
        """
        è·å–ä¸‹æ¬¡APIè°ƒç”¨çš„é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        
        :return: é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        """
        if self.is_extended_interval:
            # å»¶é•¿é—´éš”ï¼š2-4åˆ†é’Ÿ
            interval = random.randint(self.extended_min, self.extended_max)
            print(f"â±ï¸  ä½¿ç”¨å»¶é•¿é—´éš”: {interval}ç§’ ({interval//60}åˆ†{interval%60}ç§’)")
        else:
            # æ­£å¸¸é—´éš”ï¼š1-2åˆ†é’Ÿ
            interval = random.randint(self.normal_min, self.normal_max)
            print(f"â±ï¸  ä½¿ç”¨æ­£å¸¸é—´éš”: {interval}ç§’ ({interval//60}åˆ†{interval%60}ç§’)")
        
        return interval
    
    def record_success(self):
        """è®°å½•æˆåŠŸè°ƒç”¨ï¼Œé‡ç½®å¤±è´¥è®¡æ•°å’Œé—´éš”"""
        if self.consecutive_failures > 0:
            print(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°ï¼ˆä¹‹å‰è¿ç»­å¤±è´¥{self.consecutive_failures}æ¬¡ï¼‰")
        self.consecutive_failures = 0
        self.is_extended_interval = False
        self.last_failure_time = None
    
    def record_failure(self):
        """è®°å½•å¤±è´¥è°ƒç”¨ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å»¶é•¿é—´éš”"""
        self.consecutive_failures += 1
        self.last_failure_time = datetime.now()
        
        print(f"âŒ APIè°ƒç”¨å¤±è´¥ï¼Œè¿ç»­å¤±è´¥æ¬¡æ•°: {self.consecutive_failures}/{self.failure_threshold}")
        
        if self.consecutive_failures >= self.failure_threshold:
            if not self.is_extended_interval:
                print(f"âš ï¸  è¿ç»­å¤±è´¥{self.failure_threshold}æ¬¡ï¼Œå°†å»¶é•¿é—´éš”å¹¶ç­‰å¾…{self.failure_wait_time//60}åˆ†é’Ÿ")
                self.is_extended_interval = True
                return True  # éœ€è¦ç­‰å¾…
        return False  # ä¸éœ€è¦ç­‰å¾…
    
    def wait_after_failures(self):
        """è¿ç»­å¤±è´¥åçš„ç­‰å¾…"""
        if self.consecutive_failures >= self.failure_threshold:
            print(f"â³ ç­‰å¾…{self.failure_wait_time//60}åˆ†é’Ÿåç»§ç»­...")
            for i in range(self.failure_wait_time):
                if i % 60 == 0:
                    remaining = self.failure_wait_time - i
                    print(f"   å‰©ä½™ç­‰å¾…æ—¶é—´: {remaining//60}åˆ†{remaining%60}ç§’", end='\r')
                t.sleep(1)
            print(f"\nâœ… ç­‰å¾…å®Œæˆï¼Œç»§ç»­æ‰§è¡Œï¼ˆé—´éš”å·²å»¶é•¿è‡³{self.extended_min//60}-{self.extended_max//60}åˆ†é’Ÿï¼‰")


# ===== è‚¡ç¥¨åˆ—è¡¨ç®¡ç† =====
def get_all_stocks_list(cache_file: str = DEFAULT_STOCKS_LIST_FILE) -> pd.DataFrame:
    """
    è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨
    
    :param cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
    :return: DataFrameï¼ŒåŒ…å«æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä¿¡æ¯
    """
    cache_path = Path(cache_file)
    
    # å¦‚æœç¼“å­˜æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¯»å–
    if cache_path.exists():
        try:
            print(f"ğŸ“‚ ä»ç¼“å­˜æ–‡ä»¶è¯»å–è‚¡ç¥¨åˆ—è¡¨: {cache_file}")
            df = pd.read_csv(cache_file, encoding='utf-8-sig')
            print(f"âœ… æˆåŠŸè¯»å– {len(df)} åªè‚¡ç¥¨")
            return df
        except Exception as e:
            print(f"âš ï¸  è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
    
    # å¦‚æœç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥ï¼Œä»æ¥å£è·å–
    print("ğŸ“¥ æ­£åœ¨ä»æ¥å£è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
    try:
        df = ak.stock_zh_a_spot_em()
        if df is not None and not df.empty:
            # ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
            df.to_csv(cache_file, index=False, encoding='utf-8-sig')
            print(f"âœ… æˆåŠŸè·å– {len(df)} åªè‚¡ç¥¨ï¼Œå·²ä¿å­˜åˆ°: {cache_file}")
            return df
        else:
            raise Exception("è·å–çš„è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
    except Exception as e:
        print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        raise


def update_stocks_list_if_needed(cache_file: str = DEFAULT_STOCKS_LIST_FILE, force_update: bool = False) -> pd.DataFrame:
    """
    å¦‚æœéœ€è¦ï¼Œæ›´æ–°è‚¡ç¥¨åˆ—è¡¨
    
    :param cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
    :param force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
    :return: DataFrameï¼ŒåŒ…å«æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä¿¡æ¯
    """
    cache_path = Path(cache_file)
    
    # å¦‚æœå¼ºåˆ¶æ›´æ–°æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡æ–°è·å–
    if force_update or not cache_path.exists():
        return get_all_stocks_list(cache_file)
    
    # å¦åˆ™ç›´æ¥è¯»å–ç¼“å­˜
    return get_all_stocks_list(cache_file)


# ===== å·²åˆ†æè‚¡ç¥¨è®°å½•ç®¡ç† =====
def load_analyzed_stocks(record_file: str = DEFAULT_ANALYZED_RECORDS_FILE) -> Dict[str, str]:
    """
    åŠ è½½å·²åˆ†æè‚¡ç¥¨è®°å½•
    
    :param record_file: è®°å½•æ–‡ä»¶è·¯å¾„
    :return: å­—å…¸ï¼Œæ ¼å¼ä¸º {"è‚¡ç¥¨ä»£ç ": "åˆ†ææ—¥æœŸæ—¶é—´"}
    """
    record_path = Path(record_file)
    
    if record_path.exists():
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
            print(f"ğŸ“‹ åŠ è½½å·²åˆ†æè‚¡ç¥¨è®°å½•: {len(records)} åª")
            return records
        except Exception as e:
            print(f"âš ï¸  åŠ è½½å·²åˆ†æè®°å½•å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°è®°å½•")
    
    return {}


def save_analyzed_stocks(record_file: str, records: Dict[str, str]):
    """
    ä¿å­˜å·²åˆ†æè‚¡ç¥¨è®°å½•
    
    :param record_file: è®°å½•æ–‡ä»¶è·¯å¾„
    :param records: è®°å½•å­—å…¸
    """
    try:
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(records, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ ä¿å­˜å·²åˆ†æè®°å½•å¤±è´¥: {e}")


def is_stock_analyzed(stock_code: str, records: Dict[str, str]) -> bool:
    """
    æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦å·²åˆ†æ
    
    :param stock_code: è‚¡ç¥¨ä»£ç 
    :param records: å·²åˆ†æè®°å½•å­—å…¸
    :return: Trueè¡¨ç¤ºå·²åˆ†æï¼ŒFalseè¡¨ç¤ºæœªåˆ†æ
    """
    return stock_code in records


def mark_stock_analyzed(stock_code: str, record_file: str, records: Dict[str, str], logger: logging.Logger = None):
    """
    æ ‡è®°è‚¡ç¥¨ä¸ºå·²åˆ†æ
    
    :param stock_code: è‚¡ç¥¨ä»£ç 
    :param record_file: è®°å½•æ–‡ä»¶è·¯å¾„
    :param records: å·²åˆ†æè®°å½•å­—å…¸ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
    :param logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
    """
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    records[stock_code] = timestamp
    save_analyzed_stocks(record_file, records)
    if logger:
        logger.info(f"å·²æ ‡è®°è‚¡ç¥¨ {stock_code} ä¸ºå·²åˆ†æï¼ˆ{timestamp}ï¼‰")
    else:
        print(f"âœ… å·²æ ‡è®°è‚¡ç¥¨ {stock_code} ä¸ºå·²åˆ†æï¼ˆ{timestamp}ï¼‰")


def get_unanalyzed_stocks(all_stocks_df: pd.DataFrame, analyzed_records: Dict[str, str]) -> List[str]:
    """
    è·å–æœªåˆ†æçš„è‚¡ç¥¨åˆ—è¡¨
    
    :param all_stocks_df: æ‰€æœ‰è‚¡ç¥¨DataFrame
    :param analyzed_records: å·²åˆ†æè®°å½•å­—å…¸
    :return: æœªåˆ†æçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰
    """
    all_stock_codes = all_stocks_df['ä»£ç '].tolist()
    # ç¡®ä¿è‚¡ç¥¨ä»£ç è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹
    unanalyzed = [str(code) for code in all_stock_codes if not is_stock_analyzed(str(code), analyzed_records)]
    return unanalyzed


def reset_daily_records_if_needed(record_file: str, records: Dict[str, str]) -> Dict[str, str]:
    """
    å¦‚æœéœ€è¦ï¼Œæ¯æ—¥é‡ç½®å·²åˆ†æè®°å½•ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
    
    :param record_file: è®°å½•æ–‡ä»¶è·¯å¾„
    :param records: å½“å‰è®°å½•å­—å…¸
    :return: æ›´æ–°åçš„è®°å½•å­—å…¸
    """
    # æ£€æŸ¥æœ€åä¸€æ¡è®°å½•çš„æ—¶é—´
    if not records:
        return records
    
    # è·å–ä»Šå¤©çš„æ—¥æœŸ
    today = date.today().strftime('%Y-%m-%d')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä»Šå¤©çš„è®°å½•
    has_today_record = any(today in timestamp for timestamp in records.values())
    
    # å¦‚æœæ²¡æœ‰ä»Šå¤©çš„è®°å½•ï¼Œè¯´æ˜æ˜¯æ–°çš„ä¸€å¤©ï¼Œå¯ä»¥é€‰æ‹©é‡ç½®
    # è¿™é‡Œæš‚æ—¶ä¸å®ç°è‡ªåŠ¨é‡ç½®ï¼Œä¿ç•™å†å²è®°å½•
    # å¦‚æœéœ€è¦æ¯æ—¥é‡ç½®ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
    # if not has_today_record:
    #     print("ğŸ”„ æ–°çš„ä¸€å¤©ï¼Œé‡ç½®å·²åˆ†æè®°å½•")
    #     records = {}
    #     save_analyzed_stocks(record_file, records)
    
    return records


# ===== æ—¶é—´åˆ¤æ–­ =====
def is_execution_time(start_hour: int = 17, end_hour: int = 6) -> bool:
    """
    åˆ¤æ–­å½“å‰æ—¶é—´æ˜¯å¦åœ¨æ‰§è¡Œæ—¶é—´èŒƒå›´å†…ï¼ˆ17:00-æ¬¡æ—¥6:00ï¼‰
    
    :param start_hour: å¼€å§‹æ—¶é—´ï¼ˆå°æ—¶ï¼‰
    :param end_hour: ç»“æŸæ—¶é—´ï¼ˆå°æ—¶ï¼‰
    :return: Trueè¡¨ç¤ºåœ¨æ‰§è¡Œæ—¶é—´èŒƒå›´å†…
    """
    now = datetime.now()
    current_hour = now.hour
    
    # 17:00-23:59 æˆ– 00:00-06:00
    if current_hour >= start_hour or current_hour < end_hour:
        return True
    return False


def get_time_until_execution(start_hour: int = 17) -> int:
    """
    è·å–è·ç¦»æ‰§è¡Œæ—¶é—´çš„ç§’æ•°
    
    :param start_hour: å¼€å§‹æ—¶é—´ï¼ˆå°æ—¶ï¼‰
    :return: éœ€è¦ç­‰å¾…çš„ç§’æ•°
    """
    now = datetime.now()
    current_hour = now.hour
    
    # å¦‚æœå½“å‰æ—¶é—´å·²ç»åœ¨æ‰§è¡Œæ—¶é—´èŒƒå›´å†…ï¼Œè¿”å›0
    if is_execution_time(start_hour):
        return 0
    
    # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªæ‰§è¡Œæ—¶é—´ç‚¹çš„ç§’æ•°
    if current_hour < start_hour:
        # ä»Šå¤©è¿˜æ²¡åˆ°17:00ï¼Œç­‰å¾…åˆ°ä»Šå¤©17:00
        target_time = now.replace(hour=start_hour, minute=0, second=0, microsecond=0)
    else:
        # å·²ç»è¿‡äº†17:00ä½†è¿˜æ²¡åˆ°æ¬¡æ—¥6:00ï¼Œè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼ˆå› ä¸ºis_execution_timeä¼šè¿”å›Trueï¼‰
        # ä½†ä¸ºäº†å®‰å…¨ï¼Œè®¡ç®—åˆ°æ˜å¤©17:00
        target_time = (now + timedelta(days=1)).replace(hour=start_hour, minute=0, second=0, microsecond=0)
    
    delta = target_time - now
    return int(delta.total_seconds())


def wait_until_execution_time(start_hour: int = 17, check_interval: int = 60):
    """
    ç­‰å¾…ç›´åˆ°æ‰§è¡Œæ—¶é—´
    
    :param start_hour: å¼€å§‹æ—¶é—´ï¼ˆå°æ—¶ï¼‰
    :param check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    """
    while not is_execution_time(start_hour):
        wait_seconds = get_time_until_execution(start_hour)
        if wait_seconds > check_interval:
            wait_seconds = check_interval
        
        print(f"â³ å½“å‰æ—¶é—´ä¸åœ¨æ‰§è¡ŒèŒƒå›´å†…ï¼Œç­‰å¾… {wait_seconds} ç§’åæ£€æŸ¥...")
        for i in range(wait_seconds):
            if i % 60 == 0:
                remaining = wait_seconds - i
                print(f"   å‰©ä½™ç­‰å¾…æ—¶é—´: {remaining}ç§’", end='\r')
            t.sleep(1)
        print()  # æ¢è¡Œ

def preserv_zeros(value,length=8):
    import pandas as pd
    if pd.isna(value):
        return value
    value = str(value).strip
    if value.isdigit():
        return value.zfill(length)
    return value


# ===== äº¤æ˜“æ—¥å’Œåˆ†ææ¨¡å¼åˆ¤æ–­ =====
def is_today_trading_day() -> bool:
    """
    åˆ¤æ–­ä»Šå¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥

    :return: Trueè¡¨ç¤ºä»Šå¤©æ˜¯äº¤æ˜“æ—¥
    """
    from anaByQwen2 import get_trading_dates
    today_str = date.today().strftime('%Y%m%d')

    try:
        trading_dates = get_trading_dates(today_str, today_str)
        return today_str in trading_dates
    except Exception as e:
        print(f"âš ï¸ åˆ¤æ–­ä»Šå¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œé»˜è®¤è®¤ä¸ºä»Šå¤©æ˜¯äº¤æ˜“æ—¥")
        return True


def is_next_day_trading_day() -> bool:
    """
    åˆ¤æ–­ä¸‹ä¸€ä¸ªè‡ªç„¶æ—¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥

    :return: Trueè¡¨ç¤ºä¸‹ä¸€ä¸ªæ—¥æœŸæ˜¯äº¤æ˜“æ—¥
    """
    from anaByQwen2 import get_trading_dates
    tomorrow = (date.today() + timedelta(days=1)).strftime('%Y%m%d')
    today_str = date.today().strftime('%Y%m%d')

    try:
        # è·å–ä»Šå¤©å’Œæ˜å¤©çš„äº¤æ˜“æ—¥ä¿¡æ¯
        trading_dates = get_trading_dates(today_str, tomorrow)
        return tomorrow in trading_dates
    except Exception as e:
        print(f"âš ï¸  åˆ¤æ–­ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œé»˜è®¤è®¤ä¸ºä¸‹ä¸€ä¸ªæ—¥æœŸæ˜¯äº¤æ˜“æ—¥")
        return True


def update_stocks_list_on_trading_day(cache_file: str = DEFAULT_STOCKS_LIST_FILE) -> pd.DataFrame:
    """
    åœ¨äº¤æ˜“æ—¥å½“å¤©æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼Œè·å–æœ€æ–°çš„æ¢æ‰‹ç‡æ•°æ®

    :param cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
    :return: DataFrameï¼ŒåŒ…å«æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä¿¡æ¯
    """
    cache_path = Path(cache_file)
    today_str = date.today().strftime('%Y%m%d')

    # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦æ˜¯ä»Šå¤©çš„
    need_update = True
    if cache_path.exists():
        file_mtime = datetime.fromtimestamp(cache_path.stat().st_mtime)
        file_date = file_mtime.strftime('%Y%m%d')
        if file_date == today_str:
            print(f"ğŸ“‚ è‚¡ç¥¨åˆ—è¡¨å·²æ˜¯ä»Šå¤©çš„æ•°æ®ï¼ˆ{file_date}ï¼‰ï¼Œæ— éœ€æ›´æ–°")
            need_update = False

    if need_update:
        print(f"ğŸ“¥ äº¤æ˜“æ—¥å½“å¤©æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼Œè·å–æœ€æ–°æ¢æ‰‹ç‡æ•°æ®...")
        try:
            df = ak.stock_zh_a_spot_em()
            if df is not None and not df.empty:
                # ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
                df.to_csv(cache_file, index=False, encoding='utf-8-sig')
                print(f"âœ… æˆåŠŸè·å– {len(df)} åªè‚¡ç¥¨ï¼Œå·²ä¿å­˜åˆ°: {cache_file}")
                return df
            else:
                raise Exception("è·å–çš„è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            # å¦‚æœæ›´æ–°å¤±è´¥ï¼Œå°è¯•è¯»å–ç¼“å­˜
            if cache_path.exists():
                print(f"ğŸ“‚ è¯»å–ç¼“å­˜æ–‡ä»¶: {cache_file}")
                return pd.read_csv(cache_file, encoding='utf-8-sig')
            raise
    else:
        # è¯»å–å·²æœ‰çš„ä»Šå¤©æ•°æ®
        return pd.read_csv(cache_file, encoding='utf-8-sig')


def get_high_turnover_stocks(all_stocks_df: pd.DataFrame, turnover_threshold: float = 20.0) -> List[str]:
    """
    è·å–æ¢æ‰‹ç‡å¤§äºæŒ‡å®šé˜ˆå€¼çš„è‚¡ç¥¨åˆ—è¡¨

    :param all_stocks_df: æ‰€æœ‰è‚¡ç¥¨DataFrame
    :param turnover_threshold: æ¢æ‰‹ç‡é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
    :return: é«˜æ¢æ‰‹ç‡è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    # ç¡®ä¿æ¢æ‰‹ç‡åˆ—å­˜åœ¨
    if 'æ¢æ‰‹ç‡' not in all_stocks_df.columns:
        print("âš ï¸  è‚¡ç¥¨åˆ—è¡¨ä¸­ç¼ºå°‘'æ¢æ‰‹ç‡'åˆ—ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        return []

    # å¤„ç†å¯èƒ½çš„ç©ºå€¼å’Œéæ•°å€¼æ•°æ®
    df = all_stocks_df.copy()
    df['æ¢æ‰‹ç‡'] = pd.to_numeric(df['æ¢æ‰‹ç‡'], errors='coerce')

    # ç­›é€‰æ¢æ‰‹ç‡ > threshold çš„è‚¡ç¥¨
    high_turnover_df = df[df['æ¢æ‰‹ç‡'] > turnover_threshold]
    high_turnover_codes = high_turnover_df['ä»£ç '].astype(str).tolist()

    print(f"ğŸ“Š æ¢æ‰‹ç‡ > {turnover_threshold}% çš„è‚¡ç¥¨æœ‰ {len(high_turnover_codes)} åª")
    return high_turnover_codes


def get_current_analysis_mode() -> str:
    """
    è·å–å½“å‰åº”è¯¥ä½¿ç”¨çš„åˆ†ææ¨¡å¼

    åˆ¤æ–­é€»è¾‘ï¼š
    - å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œä¸”æ˜å¤©ä¹Ÿæ˜¯äº¤æ˜“æ—¥ â†’ high_turnoverï¼ˆè¿ç»­äº¤æ˜“æ—¥ï¼‰
    - å¦‚æœä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ â†’ all_randomï¼ˆéäº¤æ˜“æ—¥é—´éš”ï¼‰
    - å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œä½†æ˜å¤©ä¸æ˜¯äº¤æ˜“æ—¥ â†’ all_randomï¼ˆäº¤æ˜“æ—¥è¿›å…¥éäº¤æ˜“æ—¥ï¼‰

    å‡Œæ™¨æ—¶æ®µï¼ˆ00:00-06:00ï¼‰ç‰¹æ®Šå¤„ç†ï¼š
    - åªæœ‰å½“"æ˜¨å¤©æ˜¯äº¤æ˜“æ—¥ä¸”æ˜å¤©æ˜¯äº¤æ˜“æ—¥"æ—¶ â†’ high_turnoverï¼ˆè¿ç»­äº¤æ˜“æ—¥çš„å»¶ç»­ï¼‰
    - å¦åˆ™ â†’ all_random

    :return: 'high_turnover'ï¼ˆè¿ç»­äº¤æ˜“æ—¥ï¼Œåªåˆ†æé«˜æ¢æ‰‹ç‡ï¼‰æˆ– 'all_random'ï¼ˆéäº¤æ˜“æ—¥é—´éš”ï¼Œåˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼‰
    """
    current_hour = datetime.now().hour

    if current_hour < 6:
        # å‡Œæ™¨æ—¶æ®µï¼ˆ00:00-06:00ï¼‰ï¼šåªæœ‰è¿ç»­äº¤æ˜“æ—¥æ‰ç”¨high_turnover
        yesterday = (date.today() - timedelta(days=1)).strftime('%Y%m%d')
        today_str = date.today().strftime('%Y%m%d')
        try:
            from anaByQwen2 import get_trading_dates
            trading_dates = get_trading_dates(yesterday, (date.today() + timedelta(days=1)).strftime('%Y%m%d'))

            yesterday_is_trading = yesterday in trading_dates
            tomorrow_is_trading = is_next_day_trading_day()

            if yesterday_is_trading and tomorrow_is_trading:
                # æ˜¨å¤©æ˜¯äº¤æ˜“æ—¥ï¼Œæ˜å¤©ä¹Ÿæ˜¯äº¤æ˜“æ—¥ â†’ è¿ç»­äº¤æ˜“æ—¥çš„å»¶ç»­ â†’ high_turnover
                return 'high_turnover'
            else:
                # å¦åˆ™ â†’ all_random
                return 'all_random'
        except Exception as e:
            print(f"âš ï¸ åˆ¤æ–­äº¤æ˜“æ—¥çŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œé»˜è®¤ä½¿ç”¨all_random")
            return 'all_random'
    else:
        # å…¶ä»–æ—¶æ®µï¼ˆ06:00-24:00ï¼‰ï¼šåŸºäºä»Šå¤©å’Œæ˜å¤©çš„äº¤æ˜“æ—¥çŠ¶æ€
        today_str = date.today().strftime('%Y%m%d')
        try:
            from anaByQwen2 import get_trading_dates
            trading_dates = get_trading_dates(today_str, (date.today() + timedelta(days=1)).strftime('%Y%m%d'))

            today_is_trading = today_str in trading_dates
            tomorrow_is_trading = is_next_day_trading_day()

            if today_is_trading and tomorrow_is_trading:
                # ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œæ˜å¤©ä¹Ÿæ˜¯äº¤æ˜“æ—¥ â†’ è¿ç»­äº¤æ˜“æ—¥ â†’ high_turnover
                return 'high_turnover'
            else:
                # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œæˆ–è€…æ˜å¤©ä¸æ˜¯äº¤æ˜“æ—¥ â†’ all_random
                return 'all_random'
        except Exception as e:
            print(f"âš ï¸ åˆ¤æ–­äº¤æ˜“æ—¥çŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œé»˜è®¤ä½¿ç”¨all_random")
            return 'all_random'


def wait_until_next_trading_day_start(check_interval: int = 60):
    """
    ç­‰å¾…ç›´åˆ°ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ç›˜åï¼ˆ17:00ï¼‰

    :param check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    """
    print("ğŸ“… å½“å‰åˆ†æå‘¨æœŸå·²å®Œæˆï¼Œç­‰å¾…ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ç›˜å...")

    while True:
        now = datetime.now()
        current_hour = now.hour

        # åˆ¤æ–­æ˜¯å¦åœ¨æ‰§è¡Œæ—¶é—´èŒƒå›´å†…ï¼ˆ17:00-æ¬¡æ—¥6:00ï¼‰
        if is_execution_time():
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„äº¤æ˜“æ—¥ä¹‹å
            # å¦‚æœæ˜¯è¿ç»­äº¤æ˜“æ—¥æ¨¡å¼ï¼Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ç›˜åå°±å¼€å§‹
            # å¦‚æœæ˜¯éäº¤æ˜“æ—¥ï¼Œéœ€è¦ç­‰åˆ°äº¤æ˜“æ—¥ç›˜å
            print(f"âœ… å·²åˆ°è¾¾æ‰§è¡Œæ—¶é—´èŒƒå›´ï¼ˆå½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}ï¼‰")
            break

        # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
        if current_hour < 6:
            # å‡Œæ™¨0-6ç‚¹ï¼Œå·²åˆ°æ‰§è¡Œæ—¶é—´ï¼Œä½†éœ€è¦ç¡®è®¤æ˜¯å¦åˆ°äº†æ–°å‘¨æœŸ
            print(f"âœ… å·²åˆ°è¾¾æ‰§è¡Œæ—¶é—´èŒƒå›´ï¼ˆå½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}ï¼‰")
            break
        elif current_hour >= 17:
            # å·²åˆ°17:00ä¹‹åï¼Œå¯ä»¥å¼€å§‹
            print(f"âœ… å·²åˆ°è¾¾æ‰§è¡Œæ—¶é—´èŒƒå›´ï¼ˆå½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}ï¼‰")
            break
        else:
            # è¿˜æ²¡åˆ°17:00ï¼Œè®¡ç®—ç­‰å¾…æ—¶é—´
            target_time = now.replace(hour=17, minute=0, second=0, microsecond=0)
            delta = target_time - now
            wait_seconds = int(delta.total_seconds())

            # é™åˆ¶å•æ¬¡ç­‰å¾…æ—¶é—´
            if wait_seconds > check_interval:
                wait_seconds = check_interval

            print(f"â³ ç­‰å¾… {wait_seconds} ç§’åæ£€æŸ¥...")
            for i in range(wait_seconds):
                if i % 60 == 0 and i > 0:
                    remaining = wait_seconds - i
                    print(f"   å‰©ä½™ç­‰å¾…æ—¶é—´: {remaining//60}åˆ†{remaining%60}ç§’", end='\r')
                t.sleep(1)
            print() 

# ===== ä¸»æ§åˆ¶å¾ªç¯ =====
def analyze_stock(stock_code: str, 
                interval_controller: APICallIntervalController,
                analyzed_records: Dict[str, str],
                record_file: str,
                config: Dict[str, Any],
                logger: logging.Logger) -> bool:
    """
    åˆ†æå•ä¸ªè‚¡ç¥¨
    
    :param stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå­—ç¬¦ä¸²æˆ–æ•´æ•°ï¼Œä¼šè‡ªåŠ¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼‰
    :param interval_controller: APIè°ƒç”¨é—´éš”æ§åˆ¶å™¨
    :param analyzed_records: å·²åˆ†æè®°å½•å­—å…¸
    :param record_file: è®°å½•æ–‡ä»¶è·¯å¾„
    :param config: é…ç½®å­—å…¸
    :param logger: æ—¥å¿—è®°å½•å™¨
    :return: Trueè¡¨ç¤ºåˆ†ææˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥
    """
    # ç¡®ä¿ stock_code æ˜¯å­—ç¬¦ä¸²ç±»å‹
    stock_code = str(stock_code)
    stock_code = stock_code.zfill(6)
    logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨: {stock_code}")
    
    try:
        # ä» config ä¸­è·å–æ—¥æœŸèŒƒå›´å‚æ•°ï¼ˆä½¿ç”¨getæ–¹æ³•ç¡®ä¿å®‰å…¨ï¼‰
        specified_date = config.get('specified_date', '').strip() or None
        intraday_days = config.get('intraday_days', 3)

        # æ”¶ç›˜æœŸé—´æ™ºèƒ½è°ƒæ•´end_date
        if specified_date is None:  # åªæœ‰åœ¨ç”¨æˆ·æœªæŒ‡å®šæ—¥æœŸæ—¶æ‰è‡ªåŠ¨è°ƒæ•´
            current_hour = datetime.now().hour

            # æ”¶ç›˜æœŸé—´ï¼š16:00-23:59 æˆ– 00:00-08:00
            if current_hour >= 16 or current_hour < 8:
                logger.info(f"å½“å‰å¤„äºæ”¶ç›˜æœŸé—´ï¼ˆå½“å‰å°æ—¶: {current_hour}ï¼‰ï¼Œå°†æ™ºèƒ½é€‰æ‹©ç»“æŸæ—¥æœŸ")

                from anaByQwen2 import get_trading_dates
                today_str = date.today().strftime('%Y%m%d')
                # å¾€å‰æ¨è¶³å¤Ÿå¤šçš„å¤©æ¥ç¡®ä¿åŒ…å«éœ€è¦çš„äº¤æ˜“æ—¥
                search_start = (date.today() - timedelta(days=10)).strftime('%Y%m%d')
                recent_trading_dates = get_trading_dates(search_start, today_str)

                if current_hour >= 16:
                    # 16:00-23:59ï¼šä»Šå¤©çš„äº¤æ˜“å·²æ”¶ç›˜ï¼Œå¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥åˆ™ç”¨ä»Šå¤©
                    if len(recent_trading_dates) >= 1:
                        specified_date = recent_trading_dates[-1]  # æœ€åä¸€ä¸ªï¼ˆå¯èƒ½æ˜¯ä»Šå¤©ï¼‰
                        logger.info(f"ä½¿ç”¨å½“å‰äº¤æ˜“æ—¥: {specified_date}")
                else:
                    # 00:00-08:00ï¼šä»Šå¤©çš„äº¤æ˜“æœªå¼€å§‹ï¼Œä½¿ç”¨ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥
                    if len(recent_trading_dates) >= 2:
                        specified_date = recent_trading_dates[-2]  # å€’æ•°ç¬¬äºŒä¸ªï¼ˆä¸Šä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
                        logger.info(f"ä½¿ç”¨ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥: {specified_date}")
                    elif len(recent_trading_dates) >= 1:
                        specified_date = recent_trading_dates[-1]
                        logger.warning(f"ä»…æ‰¾åˆ°ä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œä½¿ç”¨: {specified_date}")

                if specified_date is None:
                    logger.warning("æœªèƒ½è·å–åˆ°äº¤æ˜“æ—¥ï¼Œå°†ä½¿ç”¨ä»Šå¤©æ—¥æœŸ")

        intraday_start_date, intraday_end_date = get_intraday_date_range(intraday_days, specified_date)
        hourly_volume_days = config.get('hourly_volume_days', intraday_days)
        hourly_start_date, hourly_end_date = get_intraday_date_range(hourly_volume_days, specified_date)
        kline_days = config.get('kline_days', 60)
        
        # åœ¨è°ƒç”¨akshareæ¥å£ä¹‹å‰ç­‰å¾…ï¼Œé¿å…APIè°ƒç”¨è¿‡å¿«è¢«å°IP
        # ä½¿ç”¨analyzeconfig.jsonä¸­çš„normal_min_intervalå’Œnormal_max_intervalä½œä¸ºç­‰å¾…æ—¶é—´ï¼ˆ1-2åˆ†é’Ÿï¼‰
        api_control = config.get('api_control', {})
        wait_min = api_control.get('normal_min_interval', 60)  # é»˜è®¤1åˆ†é’Ÿ
        wait_max = api_control.get('normal_max_interval', 120)  # é»˜è®¤2åˆ†é’Ÿ
        wait_time = random.randint(wait_min, wait_max)
        logger.info(f"â³ ç­‰å¾… {wait_time} ç§’ï¼ˆ{wait_time//60}åˆ†{wait_time%60}ç§’ï¼‰åå¼€å§‹è·å–è‚¡ç¥¨æ•°æ®ï¼Œé¿å…APIè°ƒç”¨è¿‡å¿«è¢«å°IP...")
        for i in range(wait_time):
            if i % 60 == 0 and i > 0:
                remaining = wait_time - i
                logger.info(f"   å‰©ä½™ç­‰å¾…æ—¶é—´: {remaining//60}åˆ†{remaining%60}ç§’")
            t.sleep(1)
        logger.info("âœ… ç­‰å¾…å®Œæˆï¼Œå¼€å§‹è·å–è‚¡ç¥¨æ•°æ®")
        
        # 1. ä¸‹è½½è‚¡ç¥¨æ•°æ®
        logger.info("æ­£åœ¨ä¸‹è½½è‚¡ç¥¨æ•°æ®...")
        result = get_and_save_stock_data(
            stock=stock_code,
            start_date=intraday_start_date,
            end_date=intraday_end_date,
            kline_days=kline_days,
            hourly_start_date=hourly_start_date,
            hourly_end_date=hourly_end_date
        )
        
        if result[0] is None:
            logger.error(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸‹è½½å¤±è´¥")
            interval_controller.record_failure()
            cleanup_stock_data(stock_code)
            return False
        
        file_paths, stock_name = result
        interval_controller.record_success()
        
        # 2. ä¸Šä¼ æ–‡ä»¶å¹¶è·å– file_id
        logger.info("æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...")
        main_file_path = file_paths['complete']
        api_key = config.get('qwen_api_key', config.get('api_key', ''))
        file_id = upload_file(file_path=main_file_path, api_key=api_key)
        
        if file_id is None:
            logger.error(f"è‚¡ç¥¨ {stock_code} çš„æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
            cleanup_stock_data(stock_code)
            interval_controller.record_failure()
            return False
        
        # 3. å¤§æ¨¡å‹åˆ†æ
        logger.info("æ­£åœ¨è¿›è¡Œå¤§æ¨¡å‹åˆ†æ...")
        prompt_template = select_prompt_by_model(config)
        response = chat_with_qwen(
            file_id=file_id,
            question=prompt_template,
            api_key=api_key,
            intraday_days=intraday_days,
            kline_days=kline_days,
            stock_code=stock_code,
            specified_date=specified_date,
            hourly_volume_days=hourly_volume_days
        )
        
        if not response:
            logger.error(f"è‚¡ç¥¨ {stock_code} å¤§æ¨¡å‹åˆ†æå¤±è´¥")
            cleanup_stock_data(stock_code)
            return False
        
        # 4. ä¿å­˜åˆ†æç»“æœåˆ°MDæ–‡ä»¶
        logger.info("æ­£åœ¨ä¿å­˜åˆ†æç»“æœ...")
        current_time = datetime.now()
        date_str = current_time.strftime('%Y%m%d')
        time_str = current_time.strftime('%H%M%S')
        
        output_dir = get_stock_output_dir(stock_code)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        clean_stock_name = stock_name.replace('(', '').replace(')', '').replace(' ', '_')
        md_filename = f"{stock_code}_{clean_stock_name}_{intraday_start_date}_to_{intraday_end_date}_{date_str}_{time_str}.md"
        md_filepath = output_dir / md_filename
        
        with open(md_filepath, 'w', encoding='utf-8') as f:
            f.write(f"# {stock_name}ï¼ˆ{stock_code}ï¼‰è‚¡ç¥¨åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {current_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            f.write(f"---\n\n")
            f.write(response)
        
        logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {md_filepath}")
        
        # 5. è½¬æ¢ä¸ºHTML
        logger.info("æ­£åœ¨è½¬æ¢ä¸ºHTML...")
        html_filename = md_filename.replace('.md', '.html')
        html_filepath = output_dir / html_filename
        converter = MarkdownToHTMLConverter()
        if not converter.convert_file(str(md_filepath), str(html_filepath)):
            logger.error(f"HTMLè½¬æ¢å¤±è´¥: {md_filepath}")
            cleanup_stock_data(stock_code)
            return False
        
        logger.info(f"HTMLæ–‡ä»¶å·²ç”Ÿæˆ: {html_filepath}")

        # 6. å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆä»…é’ˆå¯¹å¼ºçƒˆæ¨èï¼‰
        # æå–æŠ•èµ„è¯„çº§å¹¶æ·»åŠ åˆ°é‚®ä»¶ä¸»é¢˜ä¸­
        investment_rating = extract_investment_rating(str(md_filepath))

        logger.info("æ­£åœ¨æ£€æŸ¥æŠ•èµ„è¯„çº§...")
        if investment_rating and "å¼ºçƒˆæ¨è" in investment_rating:
            logger.info(f"æŠ•èµ„è¯„çº§ä¸ºã€Œ{investment_rating}ã€ï¼Œç¬¦åˆé‚®ä»¶å‘é€æ¡ä»¶ï¼Œæ­£åœ¨å‘é€é‚®ä»¶...")
            email_sender = config.get('email_sender', '')
            email_password = config.get('email_password', '')
            email_receivers = config.get('email_receivers', [])

            email_subject = f"è‚¡ç¥¨ {stock_name}ï¼ˆ{stock_code}ï¼‰åˆ†æç»“æœ - {investment_rating}"

            email_body = f"è‚¡ç¥¨ {stock_name}ï¼ˆ{stock_code}ï¼‰çš„åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹é™„ä»¶ä¸­çš„æ–‡ä»¶ã€‚\n\né™„ä»¶åŒ…å«ï¼š\n1. ä¸»åˆ†ææŠ¥å‘Šï¼ˆHTMLæ ¼å¼ï¼‰\n2. å°æ—¶é‡èƒ½åˆ†ææ•°æ®å·²åŒ…å«åœ¨CSVæ–‡ä»¶ä¸­"
            attachment_list = [str(html_filepath), str(md_filepath)]

            email_sent = send_email(
                subject=email_subject,
                body=email_body,
                receivers=email_receivers,
                sender=email_sender,
                password=email_password,
                attachment_paths=attachment_list
            )

            if not email_sent:
                logger.warning(f"è‚¡ç¥¨ {stock_code} é‚®ä»¶å‘é€å¤±è´¥ï¼Œä½†åˆ†æå·²å®Œæˆ")
            else:
                logger.info(f"è‚¡ç¥¨ {stock_code} é‚®ä»¶å‘é€æˆåŠŸ")
        else:
            rating_info = investment_rating if investment_rating else "æœªè¯†åˆ«"
            logger.info(f"æŠ•èµ„è¯„çº§ä¸ºã€Œ{rating_info}ã€ï¼Œä¸æ»¡è¶³å‘é€æ¡ä»¶ï¼ˆä»…å¼ºçƒˆæ¨èå‘é€ï¼‰ï¼Œè·³è¿‡é‚®ä»¶å‘é€")
        
        # 7. æ¸…ç†æ•°æ®ç›®å½•
        cleanup_stock_data(stock_code)
        
        # 8. æ ‡è®°ä¸ºå·²åˆ†æ
        mark_stock_analyzed(stock_code, record_file, analyzed_records)
        
        logger.info(f"è‚¡ç¥¨ {stock_code} åˆ†æå®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"è‚¡ç¥¨ {stock_code} åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        interval_controller.record_failure()
        # ç¡®ä¿åœ¨å‡ºé”™æ—¶ä¹Ÿæ¸…ç†æ•°æ®
        try:
            cleanup_stock_data(stock_code)
        except:
            pass
        return False


def setup_logging(log_file: str = DEFAULT_LOG_FILE) -> logging.Logger:
    """
    è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
    
    :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
    :return: æ—¥å¿—è®°å½•å™¨
    """
    # åˆ›å»ºæ—¥å¿—ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    log_dir = Path(log_file).parent
    if not log_dir.exists():
        log_dir.mkdir(parents=True, exist_ok=True)
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»º rotating file handler
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setFormatter(formatter)
    
    # åˆ›å»º console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    
    # åˆ›å»º logger
    logger = logging.getLogger('auto_analyze_stocks')
    logger.setLevel(logging.INFO)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger


def load_config_with_validation(config_file: str = DEFAULT_CONFIG_FILE, keys_file: str = DEFAULT_KEYS_FILE) -> Dict[str, Any]:
    """
    åŠ è½½å¹¶éªŒè¯é…ç½®æ–‡ä»¶
    
    :param config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    :param keys_file: å¯†é’¥æ–‡ä»¶è·¯å¾„
    :return: é…ç½®å­—å…¸
    :raises: FileNotFoundError, ValueError
    """
    # åŠ è½½é…ç½®æ–‡ä»¶
    if not Path(config_file).exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨")
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        raise ValueError(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
    
    # åŠ è½½å¯†é’¥æ–‡ä»¶
    if not Path(keys_file).exists():
        raise FileNotFoundError(f"å¯†é’¥æ–‡ä»¶ {keys_file} ä¸å­˜åœ¨")
    
    try:
        with open(keys_file, 'r', encoding='utf-8') as f:
            keys = json.load(f)
    except Exception as e:
        raise ValueError(f"å¯†é’¥æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
    
    # éªŒè¯å¿…è¦é…ç½®é¡¹
    required_keys = ['execution_time', 'api_control', 'analysis']
    for key in required_keys:
        if key not in config:
            raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹: {key}")
    
    # éªŒè¯æ‰§è¡Œæ—¶é—´é…ç½®
    exec_time = config['execution_time']
    if 'start_hour' not in exec_time or 'end_hour' not in exec_time:
        raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘æ‰§è¡Œæ—¶é—´é…ç½®")
    
    # éªŒè¯APIæ§åˆ¶é…ç½®
    api_control = config['api_control']
    required_api_keys = ['normal_min_interval', 'normal_max_interval', 
                      'extended_min_interval', 'extended_max_interval',
                      'failure_wait_time', 'failure_threshold']
    for key in required_api_keys:
        if key not in api_control:
            raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘APIæ§åˆ¶é…ç½®: {key}")
    
    # éªŒè¯åˆ†æé…ç½®
    analysis_config = config['analysis']
    required_analysis_keys = ['output_base_dir', 'max_retries', 'retry_delay', 'api_timeout']
    for key in required_analysis_keys:
        if key not in analysis_config:
            raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘åˆ†æé…ç½®: {key}")
    
    # åˆå¹¶keys.jsonä¸­çš„é…ç½®åˆ°configä¸­ï¼ˆä¸anaByQwen2.pyçš„load_configä¿æŒä¸€è‡´ï¼‰
    config.update(keys)
    
    # å°è¯•ä»anylizeconfig.jsonè¯»å–ç¼ºå¤±çš„é…ç½®é¡¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    analyze_config_file = 'anylizeconfig.json'
    if Path(analyze_config_file).exists():
        try:
            with open(analyze_config_file, 'r', encoding='utf-8') as f:
                analyze_config = json.load(f)
            # åˆå¹¶åˆ†æç›¸å…³çš„é…ç½®é¡¹
            for key in ['intraday_days', 'hourly_volume_days', 'kline_days', 'specified_date', 'prompt']:
                if key in analyze_config and key not in config:
                    config[key] = analyze_config[key]
                    print(f"âœ… ä» {analyze_config_file} è¯»å–é…ç½®é¡¹: {key}")
        except Exception as e:
            print(f"âš ï¸  è¯»å– {analyze_config_file} å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
    
    # è®¾ç½®é»˜è®¤å€¼ï¼ˆå¦‚æœé…ç½®ä¸­ä¸å­˜åœ¨ï¼‰
    config.setdefault('intraday_days', 3)
    config.setdefault('hourly_volume_days', 10)
    config.setdefault('kline_days', 60)
    config.setdefault('specified_date', '')
    
    # ä½¿ç”¨çŒ´å­è¡¥ä¸ä¿®æ”¹anaByQwen2.pyä¸­çš„ç­‰å¾…æ—¶é—´å¸¸é‡ï¼Œç¡®ä¿APIè°ƒç”¨é—´éš”ä¸º1-2åˆ†é’Ÿ
    # ä»é…ç½®ä¸­è¯»å–ç­‰å¾…æ—¶é—´ï¼ˆä½¿ç”¨normal_min_intervalå’Œnormal_max_intervalï¼Œå³1-2åˆ†é’Ÿï¼‰
    api_control = config.get('api_control', {})
    wait_min = api_control.get('normal_min_interval', 60)  # é»˜è®¤1åˆ†é’Ÿ
    wait_max = api_control.get('normal_max_interval', 120)  # é»˜è®¤2åˆ†é’Ÿ
    anaByQwen2.RANDOM_WAIT_MIN = wait_min
    anaByQwen2.RANDOM_WAIT_MAX = wait_max
    print(f"âœ… å·²è®¾ç½®APIè°ƒç”¨é—´éš”ä¸º {wait_min}-{wait_max} ç§’ï¼ˆ{wait_min//60}-{wait_max//60}åˆ†é’Ÿï¼‰")
    
    return config


def main_control_loop(logger: logging.Logger, debug_mode: bool = False):
    """
    ä¸»æ§åˆ¶å¾ªç¯

    åŠŸèƒ½ï¼š
    - æŒç»­è¿è¡Œï¼Œç›´åˆ°äººå·¥å¹²é¢„é€€å‡º
    - åœ¨æ‰§è¡Œæ—¶é—´èŒƒå›´å†…åˆ†æè‚¡ç¥¨
    - æ ¹æ®æ˜¯å¦ä¸ºè¿ç»­äº¤æ˜“æ—¥é€‰æ‹©ä¸åŒçš„åˆ†ææ¨¡å¼ï¼š
      * è¿ç»­äº¤æ˜“æ—¥ï¼šåªåˆ†ææ¢æ‰‹ç‡ > 20% çš„è‚¡ç¥¨
      * éäº¤æ˜“æ—¥é—´éš”ï¼šå¯¹æ‰€æœ‰è‚¡ç¥¨éšæœºåˆ†æ
    - ç®¡ç†åˆ†æè¿›åº¦å’ŒçŠ¶æ€

    :param logger: æ—¥å¿—è®°å½•å™¨
    :param debug_mode: è°ƒè¯•æ¨¡å¼ï¼Œå¦‚æœä¸ºTrueåˆ™è·³è¿‡æ—¶é—´æ£€æµ‹ï¼Œç«‹å³æ‰§è¡Œ
    """
    if debug_mode:
        logger.info("ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼šè·³è¿‡æ—¶é—´æ£€æµ‹ï¼Œç«‹å³æ‰§è¡Œ")
    logger.info("è‡ªåŠ¨è‚¡ç¥¨åˆ†æç³»ç»Ÿå¯åŠ¨")
    logger.info("=" * 50)

    try:
        # 1. åŠ è½½é…ç½®
        config = load_config_with_validation()
        logger.info("é…ç½®åŠ è½½å®Œæˆ")

        # 2. åœ¨äº¤æ˜“æ—¥å½“å¤©æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼ˆè·å–æœ€æ–°æ¢æ‰‹ç‡ï¼‰
        all_stocks_df = update_stocks_list_on_trading_day()
        logger.info(f"å…±æœ‰ {len(all_stocks_df)} åªè‚¡ç¥¨")

        # 3. åŠ è½½å·²åˆ†æè®°å½•
        analyzed_records = load_analyzed_stocks()
        analyzed_records = reset_daily_records_if_needed(DEFAULT_ANALYZED_RECORDS_FILE, analyzed_records)

        # 4. åˆå§‹åŒ–APIé—´éš”æ§åˆ¶å™¨
        api_control = config['api_control']
        interval_controller = APICallIntervalController(
            normal_min=api_control['normal_min_interval'],
            normal_max=api_control['normal_max_interval'],
            extended_min=api_control['extended_min_interval'],
            extended_max=api_control['extended_max_interval'],
            failure_wait_time=api_control['failure_wait_time'],
            failure_threshold=api_control['failure_threshold']
        )

        # 5. ä¸»å¾ªç¯
        # è®°å½•çŠ¶æ€ï¼Œç”¨äºæ£€æµ‹æ–°çš„åˆ†æå‘¨æœŸ
        last_execution_time = False  # ä¸Šä¸€æ¬¡æ˜¯å¦åœ¨æ‰§è¡Œæ—¶é—´å†…
        last_analysis_mode = None  # ä¸Šä¸€æ¬¡çš„åˆ†ææ¨¡å¼
        last_analysis_date = None  # ä¸Šä¸€æ¬¡åˆ†æçš„æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
        is_first_iteration = True  # æ˜¯å¦æ˜¯ç¬¬ä¸€æ¬¡è¿­ä»£ï¼ˆç”¨äºå¤„ç†é‡å¯ï¼‰

        while True:
            current_date = date.today()
            current_date_str = current_date.strftime('%Y-%m-%d')

            # è·å–å½“å‰åˆ†ææ¨¡å¼
            current_analysis_mode = get_current_analysis_mode()

            # æ ¹æ®æ¨¡å¼åˆ¤æ–­æ˜¯å¦åœ¨æ‰§è¡Œæ—¶é—´ï¼š
            # - all_randomæ¨¡å¼ï¼šå…¨å¤©æ‰§è¡Œï¼ˆ00:00-24:00ï¼‰ï¼Œä¸é—´æ–­åˆ†æ
            # - high_turnoveræ¨¡å¼ï¼š17:00-æ¬¡æ—¥06:00æ‰§è¡Œ
            if current_analysis_mode == 'all_random':
                current_execution_time = True  # å…¨å¤©éƒ½åœ¨æ‰§è¡Œæ—¶é—´å†…
            else:
                current_execution_time = is_execution_time()  # 17:00-06:00

            # æ£€æµ‹æ˜¯å¦è¿›å…¥æ–°çš„åˆ†æå‘¨æœŸï¼š
            # 1. ä»éæ‰§è¡Œæ—¶é—´è¿›å…¥æ‰§è¡Œæ—¶é—´ï¼ˆ17:00å¼€å§‹ï¼‰
            # 2. åˆ†ææ¨¡å¼å‘ç”Ÿå˜åŒ–
            # 3. æ—¥æœŸå‘ç”Ÿå˜åŒ–ï¼ˆæ¯ä¸ªäº¤æ˜“æ—¥éƒ½æ˜¯æ–°å‘¨æœŸï¼‰
            # æ³¨æ„ï¼šé¦–æ¬¡å¯åŠ¨æˆ–é‡å¯æ—¶ï¼Œä¼šåŠ è½½ä¹‹å‰çš„è®°å½•å¹¶ç»§ç»­ï¼ˆä¸é‡ç½®ï¼‰
            is_new_cycle = False

            if not is_first_iteration:
                # éé¦–æ¬¡è¿­ä»£ï¼Œæ­£å¸¸åˆ¤æ–­æ–°å‘¨æœŸ
                if current_execution_time and not last_execution_time:
                    # ä»éæ‰§è¡Œæ—¶é—´è¿›å…¥æ‰§è¡Œæ—¶é—´ï¼ˆå¦‚17:00å¼€å§‹ï¼‰
                    # è¿™é€šå¸¸æ„å‘³ç€æ–°çš„ä¸€å¤©æˆ–æ–°å‘¨æœŸçš„å¼€å§‹
                    is_new_cycle = True
                    logger.info(f"ğŸ”„ è¿›å…¥æ‰§è¡Œæ—¶é—´ï¼ˆ17:00å¼€å§‹ï¼‰ï¼Œæ–°çš„åˆ†æå‘¨æœŸå¼€å§‹ï¼ˆæ—¥æœŸï¼š{current_date_str}ï¼‰")
                elif current_execution_time and last_execution_time:
                    # ä¸€ç›´åœ¨æ‰§è¡Œæ—¶é—´å†…ï¼Œæ£€æŸ¥æ—¥æœŸæˆ–æ¨¡å¼æ˜¯å¦å˜åŒ–
                    date_changed = (current_date_str != last_analysis_date)
                    mode_changed = (current_analysis_mode != last_analysis_mode)

                    if date_changed:
                        # æ—¥æœŸå‘ç”Ÿå˜åŒ–ï¼Œæ–°çš„äº¤æ˜“æ—¥ï¼Œæ–°çš„åˆ†æå‘¨æœŸ
                        is_new_cycle = True
                        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ—¥æœŸå˜åŒ–ï¼ˆä» {last_analysis_date} åˆ° {current_date_str}ï¼‰ï¼Œæ–°çš„äº¤æ˜“æ—¥å‘¨æœŸå¼€å§‹")
                    elif mode_changed:
                        # æ¨¡å¼å‘ç”Ÿå˜åŒ–ï¼Œæ–°çš„åˆ†æå‘¨æœŸ
                        is_new_cycle = True
                        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°åˆ†ææ¨¡å¼å˜åŒ–ï¼ˆä» {last_analysis_mode} åˆ° {current_analysis_mode}ï¼‰ï¼Œæ–°çš„åˆ†æå‘¨æœŸå¼€å§‹")
                    else:
                        # æ—¥æœŸå’Œæ¨¡å¼éƒ½æœªå˜åŒ–ï¼Œç»§ç»­å½“å‰å‘¨æœŸ
                        logger.info(f"â¡ï¸  ç»§ç»­å½“å‰åˆ†æå‘¨æœŸï¼ˆæ—¥æœŸï¼š{current_date_str}ï¼Œæ¨¡å¼ï¼š{current_analysis_mode}ï¼‰")
            else:
                # é¦–æ¬¡è¿­ä»£ï¼ŒåŠ è½½ä¹‹å‰çš„è®°å½•å¹¶ç»§ç»­ï¼ˆä¸é‡ç½®ï¼‰
                logger.info(f"ğŸš€ é¦–æ¬¡å¯åŠ¨/é‡å¯ï¼ŒåŠ è½½ç°æœ‰è®°å½•å¹¶ç»§ç»­åˆ†æï¼ˆæ—¥æœŸï¼š{current_date_str}ï¼Œæ¨¡å¼ï¼š{current_analysis_mode}ï¼‰")
                last_analysis_date = current_date_str  # åˆå§‹åŒ–æ—¥æœŸ
                is_first_iteration = False

            if is_new_cycle:
                analyzed_records = {}
                save_analyzed_stocks(DEFAULT_ANALYZED_RECORDS_FILE, analyzed_records)
                # æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼ˆè·å–æœ€æ–°æ¢æ‰‹ç‡æ•°æ®ï¼‰
                all_stocks_df = update_stocks_list_on_trading_day()
                logger.info(f"âœ… å·²é‡ç½®åˆ†æè®°å½•ï¼Œæ–°çš„åˆ†æå‘¨æœŸå¼€å§‹ï¼ˆæ—¥æœŸï¼š{current_date}ï¼‰")

            # æ›´æ–°çŠ¶æ€
            last_execution_time = current_execution_time
            last_analysis_mode = current_analysis_mode
            last_analysis_date = current_date_str

            # æ£€æŸ¥æ˜¯å¦åœ¨æ‰§è¡Œæ—¶é—´èŒƒå›´å†…ï¼ˆè°ƒè¯•æ¨¡å¼ä¸‹è·³è¿‡ï¼‰
            if not debug_mode and not current_execution_time:
                logger.info("å½“å‰æ—¶é—´ä¸åœ¨æ‰§è¡ŒèŒƒå›´å†…ï¼Œç­‰å¾…...")
                wait_until_next_trading_day_start()
                # ç­‰å¾…åç»§ç»­å¾ªç¯ï¼Œä¼šåœ¨ä¸‹ä¸€æ¬¡è¿­ä»£æ—¶æ£€æµ‹åˆ°æ–°å‘¨æœŸ
                continue

            # æ ¹æ®æ¨¡å¼è·å–å¾…åˆ†æè‚¡ç¥¨åˆ—è¡¨
            if current_analysis_mode == 'high_turnover':
                logger.info("ğŸ“Š å½“å‰æ¨¡å¼ï¼šè¿ç»­äº¤æ˜“æ—¥ï¼Œåªåˆ†ææ¢æ‰‹ç‡ > 20% çš„è‚¡ç¥¨")
                # è·å–é«˜æ¢æ‰‹ç‡è‚¡ç¥¨
                high_turnover_stocks = get_high_turnover_stocks(all_stocks_df, turnover_threshold=20.0)
                # ä»é«˜æ¢æ‰‹ç‡è‚¡ç¥¨ä¸­ç­›é€‰æœªåˆ†æçš„ï¼ˆä½¿ç”¨å½“å‰çš„analyzed_recordsï¼‰
                unanalyzed_stocks = [code for code in high_turnover_stocks if not is_stock_analyzed(str(code), analyzed_records)]
                logger.info(f"å¾…åˆ†æçš„é«˜æ¢æ‰‹ç‡è‚¡ç¥¨æœ‰ {len(unanalyzed_stocks)} åªï¼ˆä» {len(high_turnover_stocks)} åªé«˜æ¢æ‰‹ç‡è‚¡ç¥¨ä¸­ç­›é€‰ï¼‰")
            else:
                logger.info("ğŸ² å½“å‰æ¨¡å¼ï¼šéäº¤æ˜“æ—¥é—´éš”ï¼Œå¯¹æ‰€æœ‰è‚¡ç¥¨éšæœºåˆ†æ")
                # ä»æ‰€æœ‰è‚¡ç¥¨ä¸­ç­›é€‰æœªåˆ†æçš„
                unanalyzed_stocks = get_unanalyzed_stocks(all_stocks_df, analyzed_records)
                logger.info(f"å¾…åˆ†æçš„è‚¡ç¥¨æœ‰ {len(unanalyzed_stocks)} åª")

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰è‚¡ç¥¨éœ€è¦åˆ†æ
            if not unanalyzed_stocks:
                if current_analysis_mode == 'high_turnover':
                    logger.info("âœ… æ‰€æœ‰é«˜æ¢æ‰‹ç‡è‚¡ç¥¨éƒ½å·²åˆ†æå®Œæˆï¼Œç­‰å¾…ä¸‹ä¸€ä¸ªåˆ†æå‘¨æœŸ...")
                else:
                    logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨éƒ½å·²åˆ†æå®Œæˆï¼Œç­‰å¾…ä¸‹ä¸€ä¸ªåˆ†æå‘¨æœŸ...")

                # ç­‰å¾…ç›´åˆ°ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ç›˜å
                wait_until_next_trading_day_start()
                # ç­‰å¾…åç»§ç»­å¾ªç¯ï¼Œä¼šåœ¨ä¸‹ä¸€æ¬¡è¿­ä»£æ—¶æ£€æµ‹åˆ°æ–°å‘¨æœŸå¹¶è‡ªåŠ¨é‡ç½®
                continue

            # éšæœºé€‰æ‹©ä¸€åªè‚¡ç¥¨è¿›è¡Œåˆ†æ
            stock_to_analyze = random.choice(unanalyzed_stocks)
            logger.info(f"éšæœºé€‰æ‹©è‚¡ç¥¨: {stock_to_analyze}")

            # åˆ†æè‚¡ç¥¨
            analyze_stock(stock_to_analyze, interval_controller, analyzed_records,
                        DEFAULT_ANALYZED_RECORDS_FILE, config, logger)

            # è·å–ä¸‹ä¸€æ¬¡APIè°ƒç”¨çš„é—´éš”æ—¶é—´
            interval = interval_controller.get_next_interval()

            # ç­‰å¾…æŒ‡å®šé—´éš”æ—¶é—´
            logger.info(f"ç­‰å¾… {interval} ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡åˆ†æ...")
            t.sleep(interval)

    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        logger.error(f"\nç¨‹åºå‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        logger.error("é”™è¯¯è¯¦æƒ…:")
        logger.error(traceback.format_exc())
    finally:
        logger.info("\nç¨‹åºç»“æŸ")


# ===== ä¿¡å·å¤„ç† =====
def cleanup_resources():
    """
    æ¸…ç†ç¨‹åºèµ„æº
    """
    print("\nğŸ§¹ æ­£åœ¨æ¸…ç†ç¨‹åºèµ„æº...")
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„èµ„æºæ¸…ç†é€»è¾‘
    print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def signal_handler(sig, frame):
    """
    ä¿¡å·å¤„ç†å‡½æ•°ï¼Œç”¨äºä¼˜é›…é€€å‡º
    """
    print("\nâ¹ï¸  æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œç¨‹åºå°†é€€å‡º...")
    cleanup_resources()
    sys.exit(0)


def setup_signal_handlers():
    """
    è®¾ç½®ä¿¡å·å¤„ç†
    """
    signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C
    signal.signal(signal.SIGTERM, signal_handler)  # ç»ˆæ­¢ä¿¡å·


# ===== ä¸»å‡½æ•° =====
def main():
    """
    ä¸»å‡½æ•°
    
    å‘½ä»¤è¡Œå‚æ•°ï¼š
    - æ— å‚æ•°ï¼šæ­£å¸¸æ¨¡å¼ï¼ŒæŒ‰æ—¶é—´æ£€æµ‹æ‰§è¡Œ
    - å‚æ•°ä¸º1ï¼šè°ƒè¯•æ¨¡å¼ï¼Œè·³è¿‡æ—¶é—´æ£€æµ‹ï¼Œç«‹å³æ‰§è¡Œ
    """
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    debug_mode = False
    if len(sys.argv) > 1:
        try:
            debug_flag = int(sys.argv[1])
            if debug_flag == 1:
                debug_mode = True
                print("ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼šè·³è¿‡æ—¶é—´æ£€æµ‹ï¼Œç«‹å³æ‰§è¡Œ")
            else:
                print(f"âš ï¸  æœªçŸ¥å‚æ•°: {debug_flag}ï¼Œä½¿ç”¨æ­£å¸¸æ¨¡å¼")
        except ValueError:
            print(f"âš ï¸  æ— æ•ˆå‚æ•°: {sys.argv[1]}ï¼Œä½¿ç”¨æ­£å¸¸æ¨¡å¼")
    
    try:
        # è®¾ç½®ä¿¡å·å¤„ç†
        setup_signal_handlers()
        
        # è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
        logger = setup_logging()
        
        # è¿è¡Œä¸»æ§åˆ¶å¾ªç¯
        main_control_loop(logger, debug_mode=debug_mode)
        
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        print("ğŸ“ é”™è¯¯è¯¦æƒ…:")
        traceback.print_exc()
    finally:
        print("\nğŸ‘‹ ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()